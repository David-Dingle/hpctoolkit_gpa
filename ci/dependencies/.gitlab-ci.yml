# NB: This is a crazy pipeline to dodge fundamental flaws in Spack:
#   - `spack ci` doesn't work on multiple environments. This means we have to
#     generate one pipeline per environment concretization.
#   - Spack has to be gently massaged / heavily tainted to cross-concretize correctly.
#     This means operations spanning multiple OSs, like concretization, need to be
#     spread out across multiple jobs and containers... and thus pipelines.
#   - Spack environments are unable to unify specs in a stable and controlled manner,
#     either all specs are concretized together (and views are possible), or
#     some to none are (and views are likely to fail). So we need multiple envionments
#     to properly express our testing dependencies.
#
# In short, if done the correct and straightforward way, we would have a combinatorial
# explosion of jobs and pipelines in this file. To avoid that, we use a "Multi-Level Pipeline" (MLP)
# approach. We let `spack ci generate` generate a boatload of pipelines, but then use an automated
# script to generate a single top-level pipeline that launches all the others. This removes most of
# the combinatorial burden, leaving us with (two) trigger jobs to launch the MLP.

# Generate the abstract environments we will spin everything out from
'deps:generate':
  extends: .image rebuild job
  stage: deps:generate
  image:
    name: ghcr.io/spack/fedora37:latest
    entrypoint: ['spack-env']
  tags: [docker, linux/amd64]
  needs: []
  script:
  # Install the ./dev script in a virtual environment
  - python3 -m venv .dev_venv --clear --upgrade-deps --system-site-packages
  - .dev_venv/bin/pip install --no-cache-dir --require-virtualenv lib/dev/
  # Generate the abstract environments based on this Spack
  - mkdir -p cenv/any/
  - >-
    .dev_venv/bin/dev generate --minimum cenv/any/minimum
    --cuda=disabled --rocm=disabled --level0=disabled --gtpin=disabled
    --opencl=enabled --python=enabled --papi=both --mpi=enabled
  - >-
    .dev_venv/bin/dev generate --latest cenv/any/latest
    --cuda=disabled --rocm=disabled --level0=disabled --gtpin=disabled
    --opencl=enabled --python=enabled --papi=both --mpi=enabled
  - .dev_venv/bin/dev generate --autogen cenv/any/_autogen
  artifacts:
    paths:
    - cenv/any/

# Generate a pipeline for each combination of OS and arch.
'deps:concretize: [amd64]':
  extends: .image rebuild job
  stage: deps:concretize
  image:
    name: $IMAGE_NAME
    entrypoint: ['spack-env']
  tags: [docker, linux/$ARCH]
  needs:
  - deps:generate
  variables:
    ARCH: amd64
  parallel:
    matrix:
    - IMAGE_NAME: ghcr.io/spack/leap15:latest
      IMAGE: leap15
    - IMAGE_NAME: ghcr.io/spack/almalinux8:latest
      IMAGE: almalinux8
    - IMAGE_NAME: ghcr.io/spack/ubuntu-focal:latest
      IMAGE: ubuntu20.04
    - IMAGE_NAME: ghcr.io/spack/fedora37:latest
      IMAGE: fedora37

  script:
  # Rename the abstract environments to an OS/ARCH double for concretization
  - mv cenv/any cenv/$IMAGE-$ARCH
  # Load the target downstream buildcache (reuse is enabled)
  - spack config add -f "$SBCACHE_YAML"
  # Burn in the mirrors from the config so that they are present for the installs later
  - >-
    echo -e "_autogen\nminimum\nlatest" | xargs -P0 -I '{}' -t
    spack -e "cenv/$IMAGE-$ARCH/{}/" config add -f ci/dependencies/config/mirrors.yaml
  # Add a fake mirror to the environments to keep Spack happy
  - >-
    echo -e "_autogen\nminimum\nlatest" | xargs -P0 -I '{}' -t
    spack -e "cenv/$IMAGE-$ARCH/{}/" mirror add fake http://nowhere
  # Concretize and generate pipelines for each of the environments
  - >-
    echo -e "_autogen\nminimum\nlatest" | xargs -P0 -I '{}' -t
    spack -e "cenv/$IMAGE-$ARCH/{}/" -C ci/dependencies/config/ ci generate
    --check-index-only
    --buildcache-destination "$(spack mirror list | grep -m1 '^main-bcache ' | awk '{print $2}')"
    --artifacts-root "spack-ci-artifacts/$IMAGE-$ARCH/{}/"
    --output-file "spack-ci-artifacts/$IMAGE-$ARCH/{}/ci.yml"
  # Annotate the pipeline with the source job, for the MLP
  - >-
    echo -e "\n...\n---\nsource: {pipeline: \"$CI_PIPELINE_ID\", job: \"$CI_JOB_NAME\", name: \"$IMAGE $ARCH\"}"
    | tee -a spack-ci-artifacts/$IMAGE-$ARCH/{_autogen,minimum,latest}/ci.yml

  artifacts:
    paths:
    - cenv/
    - spack-ci-artifacts/

'deps:concretize: [arm64]':
  extends: 'deps:concretize: [amd64]'
  variables:
    ARCH: arm64
  parallel:
    matrix:
    # - IMAGE:
    #   - almalinux8
    #   - fedora37
    - IMAGE_NAME: ghcr.io/spack/ubuntu-focal:latest
      IMAGE: ubuntu20.04


# Construct a Multi-Level Pipeline that runs all the pipelines from spack ci generate
'deps:mlp: [amd64]':
  extends: .image rebuild job
  stage: deps:prep
  tags: [docker]
  image: docker.io/python:3.11-bullseye
  needs:
  - 'deps:concretize: [amd64]'
  before_script:
  - python3 -m pip install ruamel.yaml
  script:
  - >-
    ci/dependencies/mlp ci.yml
    spack-ci-artifacts/{almalinux8,fedora37,leap15,ubuntu20.04}-amd64/{_autogen,minimum,latest}/ci.yml
  artifacts:
    paths:
    - ci.yml
'deps:mlp: [arm64]':
  extends: 'deps:mlp: [amd64]'
  needs:
  - 'deps:concretize: [arm64]'
  script:
  - >-
    ci/dependencies/mlp ci.yml
    spack-ci-artifacts/ubuntu20.04-arm64/{_autogen,minimum,latest}/ci.yml


# Launch the MLP and get this done.
deps:build amd64:
  extends: .image rebuild job
  stage: deps:build
  needs: ['deps:mlp: [amd64]']
  trigger:
    strategy: depend
    include:
    - job: 'deps:mlp: [amd64]'
      artifact: ci.yml
deps:build arm64:
  extends: .image rebuild job
  stage: deps:build
  needs: ['deps:mlp: [arm64]']
  trigger:
    strategy: depend
    include:
    - job: 'deps:mlp: [arm64]'
      artifact: ci.yml
