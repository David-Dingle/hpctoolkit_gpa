# Only spawn workflows for MRs or protected branches
workflow:
  rules:
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
    when: never
  - when: always


stages:
- setup
- validate
- test
- lint


variables:
  # Most jobs require the submodules, those that don't will override this
  GIT_SUBMODULE_STRATEGY: recursive

  # Add a transfer progress bar for artifacts
  TRANSFER_METER_FREQUENCY: 2s

  # Use fastzip to package caches and artifacts
  FF_USE_FASTZIP: 'true'
  ARTIFACT_COMPRESSION_LEVEL: default
  CACHE_COMPRESSION_LEVEL: fastest

  # Retry various preliminary job stages (network errors)
  GET_SOURCES_ATTEMPTS: 3
  ARTIFACTS_DOWNLOAD_ATTEMPTS: 3
  EXECUTOR_JOB_SECTION_ATTEMPTS: 3

  DEPS_IMAGES_REPO:
    description: Sibling GitLab project to generate deps images
    value: hpctoolkit/hpctoolkit-deps

  DEPS_IMAGES:
    description: URL (prefix) of the container registries to pull deps images from
    value: registry.gitlab.com/hpctoolkit/hpctoolkit-deps


default:
  # Most jobs can be interrupted and should be retried if failed for mysterious reasons
  interruptible: true
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - stuck_or_timeout_failure
    - runner_system_failure


# Many jobs use ccache to speed up the build process. This job provides common settings for those.
.ccache job:
  cache:
  - key: ccache-$CI_JOB_NAME
    when: always
    paths:
    - .ccache/

  variables:
    CCACHE_DIR: '$CI_PROJECT_DIR/.ccache'
    CCACHE_BASEDIR: '$CI_PROJECT_DIR'
    CCACHE_NOCOMPRESS: 'true'
    CCACHE_MAXSIZE: '5G'
    CCACHE_MAXFILES: '0'

#----------------------------------------------
# Phase 1: Fetch (and if desired build) the deps images
#----------------------------------------------

# Produce the request.jsons for generating images, along with the URLs and SHA256s
request:
  stage: setup
  image: docker.io/python:3.10-bullseye
  tags: [saas-linux-small-amd64]
  script:
  - artifacts_url="$CI_API_V4_URL/projects/$CI_PROJECT_ID/jobs/$CI_JOB_ID/artifacts"

  - ./dev generate-request --any --template ci/templates/request.yaml latest.json
  - sha256sum latest.json > latest.json.sha
  - echo "DIGEST_latest=$(cut -d' ' -f1 latest.json.sha)" >> request.env
  - echo "REQUEST_URL_latest=$artifacts_url/latest.json" >> request.env

  - ./dev generate-request --minimum --template ci/templates/request.yaml minimum.json
  - sha256sum minimum.json > minimum.json.sha
  - echo "DIGEST_minimum=$(cut -d' ' -f1 minimum.json.sha)" >> request.env
  - echo "REQUEST_URL_minimum=$artifacts_url/minimum.json" >> request.env
  artifacts:
    paths:
    - latest.json
    - minimum.json
    reports:
      dotenv: request.env

# Add buttons to trigger (re-)building the dependencies images from the request.jsons
deps build:
  stage: setup
  when: manual
  needs: [request]
  trigger:
    project: $DEPS_IMAGES_REPO
    strategy: depend
  variables:
    DEPS_SOURCE: $REQUEST_URL_latest
    DEPS_BUILD: >-
      almalinux8/v1
      ubuntu20.04/v1
      fedora38/v1
      cuda/v1:10.2
      cuda/v2:11.6
      cuda/v2:11.8
      cuda/v2:12.0
      rocm/v1:5.1
      rocm/v1:5.2
      rocm/v1:5.3
      rocm/v1:5.4
      rocm/v1:5.5
      rocm/v1:5.6
      lvlz-gtpin/v1:2023.0-3.2
deps build min:
  extends: deps build
  variables:
    DEPS_SOURCE: $REQUEST_URL_minimum

#-----------------------------------
# Phase N: lint
#-----------------------------------

# Pre-commit linting passes must pass for the pipeline to succeed
precommit:
  stage: lint
  image: docker.io/python:3.10-bullseye
  needs: []
  before_script:
  - apt-get update -yqq && apt-get install -yqq git git-lfs
  - python3 -m pip install pre-commit
  script:
  - pre-commit run --all-files --show-diff-on-failure


# Check that the Spack recipe for @develop is sufficiently up-to-date to compile this branch.
# Failures are allowed for MRs so that if the dependencies or build flags shift, we are made aware
# (by a big orange exclaimation point) but not blocked by upstream Spack.
'spack install: [amd64]':
  stage: lint
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_latest
  needs:
  - job: request
  - job: validate
    artifacts: false
  tags: [saas-linux-small-amd64]
  rules:
  - if: $CI_COMMIT_REF_PROTECTED == "true"
    allow_failure: false
  - allow_failure: true
  cache:
    key: spack
    when: always
    paths: [.spack.git]
  parallel:
    matrix:
    - VARIANTS:
      # TODO: Expand this list a bit sometime to better represent what we want to ensure works
      - +papi
      - ~papi
  before_script:
  - apt-get update -yqq
  - apt-get install -yqq git git-lfs gcc g++ make patch tar gzip unzip bzip2 xz-utils zstd file gnupg2 eatmydata
  # Ensure we have Git and Git LFS
  - git --version
  - git lfs --version
  script:
  # Instantiate a fresh Spack develop (instead of whatever is burned into the image)
  - |
    if [ ! -d .spack.git ]; then
      git clone --depth=30 --single-branch --no-tags --branch=develop --bare \
        https://github.com/spack/spack.git .spack.git || exit $?
    fi
  - git -C .spack.git fetch --verbose origin +develop:develop
  - git clone --shared --branch=develop .spack.git /tmp/spack
  - export PATH=/tmp/spack/bin:"$PATH"
  # Override any generic settings that were set in the deps image
  - spack -D /opt/environment config add 'packages:hpctoolkit:require::[]'
  - spack -D /opt/environment config add 'packages:all:require::[]'
  # Register this clone of HPCToolkit as the source for Spack to build `hpctoolkit @develop-ci` from
  - spack -D /opt/environment develop --no-clone --path "$CI_PROJECT_DIR" hpctoolkit@develop-ci
  # Spack out a representative HPCToolkit. All dependencies should already be built.
  - eatmydata spack -D /opt/environment install --fail-fast --add --only=package
    "hpctoolkit @=develop-ci ~viewer ~mpi ~debug +opencl ~cuda ~rocm ~level_zero $VARIANTS"

#-----------------------------------
# Phase 2: validate
#-----------------------------------

# The two devenvs must be consistent with the current version of the ./dev scriptsuite.
validate:
  stage: validate
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_latest
  tags: [saas-linux-small-amd64]
  script:
  - ./dev os-install -y -c gcc git git-lfs file diffutils
  - &spack_clone
    - git clone --depth=1 https://github.com/spack/spack.git /tmp/spack
    - export PATH=/tmp/spack/bin/:"$PATH"
  - ./dev populate /opt/environment
  # Detect any changes to the main source directory
  - git status --porcelain=v1 --untracked-files=no > changes || exit $?
  - |
    if test -s changes; then
      echo "== CHANGES DETECTED, running git diff..."
      git diff | tee fixup.patch
      echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
      exit 1
    fi
  artifacts:
    when: always
    paths:
    - fixup.patch

#-----------------------------------
# Phase 3: test
#-----------------------------------

# Build many versions of the codebase, to ensure all the various compilations work
# As a general rule, we sweep the most-likely-to-fail configurations by turning off a single variant
# at a time. With the exception of +debug, which is flipped at will.
.buildmany:
  stage: test
  script:
  - ./dev os-install -y -c "$JOB_CC" git file diffutils tar eatmydata ccache
  - *spack_clone
  - ./dev populate -c "$JOB_CC" /opt/environment
  - mkdir -p logs/"$CI_JOB_NAME"
  - |
    build() {
      id="$1"
      logfile=logs/"$CI_JOB_NAME"/"$id".log
      shift

      echo -e "\e[32m$ ./dev meson -d /opt/environment -- configure $*\e[0m"
      ./dev meson -d /opt/environment -- configure "$@" || return $?
      echo -e "\e[32m$ ./dev meson -d /opt/environment compile && ./dev meson -d /opt/environment install\e[0m"
      { ./dev meson -d /opt/environment compile -j$(./dev nproc --soft) && ./dev meson -d /opt/environment install; } > "$logfile" 2>&1 \
        || { code=$?; cat "$logfile"; return $code; }
      echo -e "\e[32m$ ./dev validate-install -d /opt/environment\e[0m"
      ./dev validate-install -d /opt/environment || return $?
    }
  - |
    for buildtype in debugoptimized release; do
      build $buildtype-all    -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=enabled -Dopencl=enabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=true $COMMON_SETTINGS || exit $?
      build $buildtype-nopapi -Dbuildtype=$buildtype -Dpapi=disabled -Dpython=enabled -Dopencl=enabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=true $COMMON_SETTINGS || exit $?
      build $buildtype-nopy   -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=disabled -Dopencl=enabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=true $COMMON_SETTINGS || exit $?
      build $buildtype-noocl  -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=enabled -Dopencl=disabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=true $COMMON_SETTINGS || exit $?
      build $buildtype-nompi  -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=enabled -Dopencl=enabled -Dhpcprof_mpi=disabled -Dvalgrind_annotations=true $COMMON_SETTINGS || exit $?
      build $buildtype-noval  -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=enabled -Dopencl=enabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=false $COMMON_SETTINGS || exit $?
    done
  after_script:
  - |
    echo "To reproduce:"
    echo "    cd path/to/hpctoolkit"
    echo "    podman run --rm -it -v ./:/hpctoolkit -v /hpctoolkit/.devenv --workdir /hpctoolkit -e JOB_CC=$JOB_CC $CI_JOB_IMAGE"
  - ./dev cc-diagnostics cq.json logs/"$CI_JOB_NAME"/*.log
  artifacts:
    reports:
      codequality: cq.json
    paths:
    - logs/
    when: always

# CPU-only spins
.buildmany amd64 cpu:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    COMMON_SETTINGS: '-Dcuda=disabled -Drocm=disabled -Dlevel0=disabled'

'buildmany: [amd64, almalinux8]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/almalinux8/v1:latest-$DIGEST_latest
  parallel: {matrix: [{JOB_CC: gcc=8}]}
'buildmany: [amd64, ubuntu20.04]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_latest
  parallel: {matrix: [{JOB_CC: [clang-10]}]}
'buildmany: [amd64, fedora38]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/fedora38/v1:latest-$DIGEST_latest
  parallel: {matrix: [{JOB_CC: [gcc=13, clang=16]}]}

'buildmany min: [amd64, almalinux8]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/almalinux8/v1:latest-$DIGEST_minimum
  parallel: {matrix: [{JOB_CC: gcc=8}]}
'buildmany min: [amd64, ubuntu20.04]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_minimum
  parallel: {matrix: [{JOB_CC: [clang-10]}]}
'buildmany min: [amd64, fedora38]':
  extends: .buildmany amd64 cpu
  image: $DEPS_IMAGES/fedora38/v1:latest-$DIGEST_minimum
  parallel: {matrix: [{JOB_CC: [gcc=13, clang=16]}]}


# CUDA spins
.buildmany amd64 cuda:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    COMMON_SETTINGS: '-Dcuda=enabled -Drocm=disabled -Dlevel0=disabled'

'buildmany: [amd64, cuda12.0]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v2:12.0-$DIGEST_latest
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, cuda11.8]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v2:11.8-$DIGEST_latest
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, cuda10.2]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v1:10.2-$DIGEST_latest
  variables:
    JOB_CC: gcc=8

'buildmany min: [amd64, cuda12.0]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v2:12.0-$DIGEST_minimum
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, cuda11.8]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v2:11.8-$DIGEST_minimum
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, cuda10.2]':
  extends: .buildmany amd64 cuda
  image: $DEPS_IMAGES/cuda/v1:10.2-$DIGEST_latest
  variables:
    JOB_CC: gcc=8

# ROCm spins
.buildmany amd64 rocm:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    COMMON_SETTINGS: '-Dcuda=disabled -Drocm=enabled -Dlevel0=disabled'

'buildmany: [amd64, rocm5.1]':
  extends: .buildmany amd64 rocm
  image: $DEPS_IMAGES/rocm/v1:5.1-$DIGEST_latest
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, rocm5.6]':
  extends: .buildmany amd64 rocm
  image: $DEPS_IMAGES/rocm/v1:5.6-$DIGEST_latest
  variables:
    JOB_CC: gcc-9

'buildmany min: [amd64, rocm5.1]':
  extends: .buildmany amd64 rocm
  image: $DEPS_IMAGES/rocm/v1:5.1-$DIGEST_minimum
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, rocm5.6]':
  extends: .buildmany amd64 rocm
  image: $DEPS_IMAGES/rocm/v1:5.6-$DIGEST_minimum
  variables:
    JOB_CC: gcc-9

# Level 0 + GTPin spins
.buildmany amd64 lvlz:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    COMMON_SETTINGS: '-Dcuda=disabled -Drocm=disabled -Dlevel0=enabled -Dgtpin=enabled'
  script:
  - !reference [.buildmany, script]
  - |
    for buildtype in debugoptimized release; do
      build $buildtype-nogtpin -Dbuildtype=$buildtype -Dpapi=enabled -Dpython=enabled -Dopencl=enabled -Dhpcprof_mpi=enabled -Dvalgrind_annotations=true $COMMON_SETTINGS -Dgtpin=disabled || exit $?
    done

'buildmany: [amd64, lvlz2023.0, gtpin3.2]':
  extends: .buildmany amd64 lvlz
  image: $DEPS_IMAGES/lvlz-gtpin/v1:2023.0-3.2-$DIGEST_latest
  variables:
    JOB_CC: gcc-9

'buildmany min: [amd64, lvlz2023.0, gtpin3.2]':
  extends: .buildmany amd64 lvlz
  image: $DEPS_IMAGES/lvlz-gtpin/v1:2023.0-3.2-$DIGEST_minimum
  variables:
    JOB_CC: gcc-9


# Build single versions of the codebase and run unit tests through `make check`
# NB: We use --repeat in the check jobs to detect bugs that cause sporadic test failures.
# We chose --repeat 7, since this statistically provides:
#   - 99.2% confidence that this MR does not introduce a "blocking" bug that would prevent others'
#     work. We are very confident that a run will succeed >1/2 the time, and so require minimal
#     repeated commands to "push past" the issue. (`1 - pbinom(0, 7, 1 - 1/2) -> 0.992`)
#   - 79.0% confidence that this MR does not introduce a bug that would "annoy" others during their
#     work. We are modestly confident that a run will succeed >4/5 of the time, in which case the
#     bug may not be especially noticable. (`1 - pbinom(0, 7, 1 - 4/5) -> 0.790`)
#
# For the curious, the key formula to solve for the --repeat value is:
#     {# of repeats} > log(1 - {confidence}) / log({min prob of success})
# So a 99% confidence of 90% success rate requires a --repeat of at least 44.
.check:
  stage: test
  variables:
    # OpenMPI refuses to run as user 0 without these options set.
    OMPI_ALLOW_RUN_AS_ROOT: 1
    OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  script:
  - &check_setup
    - ./dev os-install -y -c "$JOB_CC" git file diffutils tar make eatmydata ccache
    - *spack_clone
    - export MESON_TESTTHREADS=$(./dev nproc --soft)
    - mkdir logs/
    - logfile=logs/"$CI_JOB_NAME".log
    - rm -f "$logfile"
    - ./dev populate -c "$JOB_CC" /opt/environment
  - &check_compile
    - ./dev meson -d /opt/environment compile -j$(./dev nproc --soft) >> "$logfile" 2>&1 || { code=$?; cat "$logfile"; exit $code; }
    - ./dev meson -d /opt/environment install >> "$logfile" 2>&1 || { code=$?; cat "$logfile"; exit $code; }
  - &check_test
    - ./dev meson -d /opt/environment test --maxfail=10 --repeat=${JOB_TEST_REPEAT:-7} ${JOB_TEST_SUITE:+--suite=$JOB_TEST_SUITE}
  after_script:
  - |
    echo "To reproduce:"
    echo "    cd path/to/hpctoolkit"
    echo "    podman run --rm -it -v ./:/hpctoolkit -v /hpctoolkit/.devenv --workdir /hpctoolkit -e JOB_CC=$JOB_CC $CI_JOB_IMAGE"
  - &check_after
    - ./dev cc-diagnostics cq.json logs/"$CI_JOB_NAME".log
    - cp -t "$CI_PROJECT_DIR"/ /opt/environment/builddir/meson-logs/testlog.junit.xml

  artifacts: &check_artifacts
    reports:
      codequality: cq.json
      junit: '*.junit.xml'
    paths:
    - logs/
    when: always
.check semifresh job:
  script:
  - *check_setup
  - *check_compile
  - ./dev meson -d /opt/environment compile $(printf 'tests2/data/fresh-testdata-%s.tar.xz\n' $REGEN_SUITES)
  - mkdir -p testdata/"$CI_JOB_NAME"
  - cp -t testdata/"$CI_JOB_NAME"/ $(printf '/opt/environment/builddir/tests2/data/fresh-testdata-%s.tar.xz\n' $REGEN_SUITES)
  - for suite in $REGEN_SUITES; do tar xJvf /opt/environment/builddir/tests2/data/fresh-testdata-$suite.tar.xz || exit $?; done
  - *check_compile
  - *check_test
  after_script:
  - |
    echo "To reproduce:"
    echo "    cd path/to/hpctoolkit"
    echo "    podman run --rm -it -v ./:/hpctoolkit -v /hpctoolkit/.devenv --workdir /hpctoolkit -e JOB_CC=$JOB_CC -e REGEN_SUITES='$REGEN_SUITES' $CI_JOB_IMAGE"
  - *check_after
  artifacts:
    <<: *check_artifacts
    paths:
    - logs/
    - testdata/

'check amd64: [cpu]':
  extends: .check
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_latest
  tags: [rice-linux-large-bare-amd64]
  variables: &vars_check_cpu
    JOB_CC: gcc-10
    SPEC: '+mpi +debug +valgrind_debug +papi +python ~opencl ~cuda ~rocm ~level0'
'check min amd64: [cpu]':
  extends: .check
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_minimum
  tags: [rice-linux-large-bare-amd64]
  variables: *vars_check_cpu
'check semifresh amd64: [cpu]':
  extends: ['check amd64: [cpu]', .check semifresh job]
  variables:
    REGEN_SUITES: none cpu

'check arm64: [cpu]':
  extends: .check
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_latest
  tags: [rice-linux-small-bare-arm64]
  variables:
    <<: *vars_check_cpu
    JOB_TEST_REPEAT: 1
'check min arm64: [cpu]':
  extends: .check
  image: $DEPS_IMAGES/ubuntu20.04/v1:latest-$DIGEST_minimum
  tags: [rice-linux-small-bare-arm64]
  variables:
    <<: *vars_check_cpu
    JOB_TEST_REPEAT: 1

'check amd64: [+cuda, 11.6]':
  extends: .check
  image: $DEPS_IMAGES/cuda/v2:11.6-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-p100]
  variables: &vars_check_cuda
    JOB_CC: gcc-9
    JOB_TEST_SUITE: cuda

'check amd64: [+cuda, 11.8]':
  extends: .check
  image: $DEPS_IMAGES/cuda/v2:11.8-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-p100]
  variables: *vars_check_cuda
'check min amd64: [+cuda, 11.8]':
  extends: .check
  image: $DEPS_IMAGES/cuda/v2:11.8-$DIGEST_minimum
  tags: [rice-linux-large-amd64-gpu-p100]
  variables: *vars_check_cuda
'check semifresh amd64: [+cuda, 11.8]':
  extends: ['check amd64: [+cuda, 11.8]', .check semifresh job]
  tags: [rice-linux-large-bare-amd64-gpu-p100]
  variables:
    REGEN_SUITES: none cpu nvidia sw-cuda

'check amd64: [+rocm, 5.1]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.1-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: &bscript_check_rocm
  - export LD_LIBRARY_PATH=/opt/rocm/lib:"$LD_LIBRARY_PATH"
  variables: &vars_check_rocm
    JOB_CC: gcc-9
    JOB_TEST_SUITE: rocm

'check amd64: [+rocm, 5.2]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.2-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: *bscript_check_rocm
  variables: *vars_check_rocm

'check amd64: [+rocm, 5.3]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.3-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: *bscript_check_rocm
  variables: *vars_check_rocm

'check amd64: [+rocm, 5.4]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.4-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: *bscript_check_rocm
  variables: *vars_check_rocm

'check amd64: [+rocm, 5.5]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.5-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: *bscript_check_rocm
  variables: *vars_check_rocm

'check amd64: [+rocm, 5.6]':
  extends: .check
  image: $DEPS_IMAGES/rocm/v1:5.6-$DIGEST_latest
  tags: [rice-linux-large-amd64-gpu-amd]
  before_script: *bscript_check_rocm
  variables: *vars_check_rocm
'check min amd64: [+rocm, 5.6]':
  extends: 'check amd64: [+rocm, 5.6]'
  image: $DEPS_IMAGES/rocm/v1:5.6-$DIGEST_minimum
'check semifresh amd64: [+rocm, 5.6]':
  extends: ['check amd64: [+rocm, 5.6]', .check semifresh job]
  tags: [rice-linux-large-bare-amd64-gpu-amd]
  variables:
    REGEN_SUITES: none cpu amd


# Repackage the fresh testdata generated during the `check semifresh` jobs
fresh testdata:
  stage: .post
  image: docker.io/alpine
  needs:
  - 'check semifresh amd64: [cpu]'
  - 'check semifresh amd64: [+cuda, 11.8]'
  - 'check semifresh amd64: [+rocm, 5.6]'
  when: always
  variables:
    GIT_SUBMODULE_STRATEGY: none
  script:
  - apk add xz
  - mkdir /tmp/result
  # Unpack all the tarballs to the temporary directory
  - "tar x -af testdata/'check semifresh amd64: [cpu]'/fresh-testdata-none.tar.xz -C /tmp/result"
  - "tar x -af testdata/'check semifresh amd64: [cpu]'/fresh-testdata-cpu.tar.xz -C /tmp/result"
  - "tar x -af testdata/'check semifresh amd64: [+cuda, 11.8]'/fresh-testdata-sw-cuda.tar.xz -C /tmp/result"
  - "tar x -af testdata/'check semifresh amd64: [+cuda, 11.8]'/fresh-testdata-nvidia.tar.xz -C /tmp/result"
  - "tar x -af testdata/'check semifresh amd64: [+rocm, 5.6]'/fresh-testdata-amd.tar.xz -C /tmp/result"
  # Repack into a single tarball
  - tar c -Jf testdata.tar.xz -C /tmp/result .
  artifacts:
    expose_as: "Regenerated test data"
    paths:
    - testdata.tar.xz
