# Only spawn workflows for MRs or protected branches
workflow:
  rules:
  - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"'
    when: never
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
    when: never
  - when: always


stages:
- validate
- dependencies
- test
- extended test
- lint
- update


include:
# Jobs for building all the dependencies with Spack
- local: ci/dependencies/.gitlab-ci.yml
# Jobs to regenerating test data when needed
- local: tests2/data/.gitlab-ci.yml


variables:
  # Add a transfer progress bar for artifacts
  TRANSFER_METER_FREQUENCY: 2s

  # Use fastzip to package caches and artifacts
  FF_USE_FASTZIP: 'true'
  ARTIFACT_COMPRESSION_LEVEL: default
  CACHE_COMPRESSION_LEVEL: fastest


default:
  # Most jobs can be interrupted and should be retried if failed for mysterious reasons
  interruptible: true
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - runner_system_failure

  # By default, use a Docker runner with a late-model CI image
  tags: [docker]
  image: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:latest


# Pre-commit linting passes must pass for the pipeline to succeed
precommit:
  stage: lint
  tags: [docker, linux/amd64]
  image: registry.gitlab.com/hpctoolkit/ci-images/selfcheck:amd64
  needs: []
  cache:
    key: precommit
    paths:
    - .pc-cache/
  script:
  - mkdir -p .pc-cache/ ~/.cache/
  - ln -s $(realpath .pc-cache/) ~/.cache/pre-commit
  - pre-commit run --all-files || { git diff | tee fixup.patch && exit 1; }
  artifacts:
    paths:
    - fixup.patch


# The Autogoo for the HEAD commit (at least) must be in-sync before we build
autoreconf:
  stage: validate
  tags: [docker, linux/amd64]
  image: registry.gitlab.com/hpctoolkit/ci-images/hpct-devtools:amd64
  needs: []
  script:
  - ./autogen > autogen.log
  - git status --porcelain=v1 --untracked-files=no > changes || exit $?
  - |
    if test -s changes; then
      echo "== CHANGES DETECTED, running git diff..."
      git diff | tee fixup.patch
      echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
      exit 1
    fi
  artifacts:
    when: always
    paths:
    - autogen.log
    - fixup.patch


# Also check that the Autogoo is in-sync for all commits that will be merged,
# but only if merged results pipelines are enabled.
autoreconf check:
  stage: lint
  tags: [docker, linux/amd64]
  image: registry.gitlab.com/hpctoolkit/ci-images/hpct-devtools:amd64
  needs:
  - autoreconf

  allow_failure: true
  variables:
    GIT_DEPTH: 100
  rules:
  - if: $CI_MERGE_REQUEST_TARGET_BRANCH_SHA
  script:
  - TARG="$(git show --no-patch --pretty=reference $CI_MERGE_REQUEST_TARGET_BRANCH_SHA)"
  - SRC="$(git show --no-patch --pretty=reference $CI_MERGE_REQUEST_SOURCE_BRANCH_SHA)"
  - MERGE="$(git show --no-patch --pretty=reference HEAD)"
  - echo "Checking commit range $TARG..$SRC + $MERGE"
  - git rev-list --topo-order --reverse HEAD ^"$CI_MERGE_REQUEST_TARGET_BRANCH_SHA" > revs
  - |
    while read rev; do
      echo
      echo "== Checking $(git show --no-patch --pretty=reference $rev)" | tee -a autogen.log
      git checkout --force "$rev" || exit $?
      git clean -fxd || exit $?
      ./autogen >> autogen.log || exit $?
      git status --porcelain=v1 --untracked-files=no > changes || exit $?
      if test -s changes; then
        echo "== CHANGES DETECTED, running git diff..."
        git diff | tee fixup.patch
        echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
        echo "== First noticed desynchronization in commit:"
        git show --no-patch --pretty=medium $rev
        exit 1
      fi
    done < revs
  artifacts:
    when: always
    paths:
    - autogen.log
    - fixup.patch

# Many jobs require Spack to function. This is the common setup pieces.
# Note that Spack may shift SHA's between jobs.
.spack:
  cache:
    key: spack
    when: always
    paths: [.spack.git]
  before_script:
  - echo -e "\e[0Ksection_start:`date +%s`:spack_clone_init[collapsed=true]\r\e[0KSpack update and initialization"
  - - export SPACK_ROOT="$(realpath .spack)"
    - ci/dependencies/spack-init.sh
    - export PATH="$SPACK_ROOT"/bin:"$PATH"
  - echo -e "\e[0Ksection_end:`date +%s`:spack_clone_init\r\e[0K"

# Build jobs require a working Spack with access to the buildcache. This (very long) job handles all
# the common setup pieces that go into that.
.buildcache-job:
  cache:
  - !reference [.spack, cache]
  - &bcjob_cache1
    key: bcjob-$CI_JOB_IMAGE
    when: always
    paths:
    - .apt-cache/
    - .pip-cache/
    - .spack-bincache-shared/
  - &bcjob_cache2
    key: bcjob-$CI_JOB_IMAGE-$CI_COMMIT_REF_SLUG
    when: always
    paths:
    - .spack-bincache-nonprotected/
  - &bcjob_cache3
    key: bcjob-$CI_JOB_IMAGE-$JOB_CC
    when: always
    paths:
    - .ccache/

  variables:
    # Limit the ccache cache size to a modest level.
    # One HPCToolkit buildmany is ~2.5GB (~600MB compressed) over ~25000 files
    CCACHE_COMPRESS: 'true'
    CCACHE_MAXSIZE: '3G'
    CCACHE_MAXFILES: '30000'

  before_script:
  # Make sure we have the basic set of utilities required to launch Spack and build stuff
  - ci/scripts/ensure-present.sh make git curl cc file patchelf python3 eatmydata py:boto3 py:clingo ${JOB_CC:+ccache}

  # Unpack and instantiate Spack here
  - !reference [.spack, before_script]

  - echo -e "\e[0Ksection_start:`date +%s`:spack_buildcache_config[collapsed=true]\r\e[0KSpack buildcache configuration"
  - - ci/dependencies/spack-bc-downstream.sh
    # Configure the local binary cache to cache binaries
    - |
      cat > .spack-bincache-config.yml <<EOF
      config:
        local_binary_cache:
        - prefixes: ['${SBCACHE_URL}/nonprotected']
          root: '${CI_PROJECT_DIR}/.spack-bincache-nonprotected/'
        - root: '${CI_PROJECT_DIR}/.spack-bincache-shared/'
      EOF
    - spack config --scope site add -f .spack-bincache-config.yml
    - rm .spack-bincache-config.yml
    # Make sure Spack has a GCC available. Oddly enough, this command will run `spack compiler find` internally,
    # but only if needed.
    - spack compiler info gcc
    # Mark down the OS and arch, as used in the concretized environment paths
    - os="$(spack arch --operating-system)"
    - |
      case "$(spack arch --generic-target)" in
      x86_64*) arch=amd64; ;;
      aarch64) arch=arm64; ;;
      ppc64le) arch=ppc64le; ;;
      *) echo "Unknown generic target: $(spack arch --generic-target)"; exit 1; ;;
      esac
    - concrete=/c/$os/$arch/
  - echo -e "\e[0Ksection_end:`date +%s`:spack_buildcache_config\r\e[0K"

  - if test -n "$JOB_CC"; then
  - - echo -e "\e[0Ksection_start:`date +%s`:ccache_init[collapsed=true]\r\e[0KCompiler and ccache initialization"
    # Derive the CC/CXX from the JOB_CC shorthand
    - |
      test -z "$JOB_CC" || case "$JOB_CC" in
      # Rocky/Fedora form, which don't ship multiple GCCs
      gcc=*)
        export CC=gcc CXX=g++
        ;;
      clang=*)
        export CC=clang CXX=clang++
        ;;
      # Debian/Ubuntu/SUSE form, which ships multiple GCCs
      gcc-*)
        export CC=gcc-"${JOB_CC##gcc-}" CXX=g++-"${JOB_CC##gcc-}"
        ;;
      clang-*)
        export CC=clang-"${JOB_CC##clang-}" CXX=clang++-"${JOB_CC##clang-}"
        ;;
      *)
        echo "Invalid compiler shorthand: $JOB_CC"
        exit 1
        ;;
      esac
    - test -z "$JOB_CC" || "$CC" --version
    - test -z "$JOB_CC" || "$CXX" --version
    # Initialize ccache
    - export CCACHE_DIR="$(realpath .ccache/)" CCACHE_BASEDIR="$CI_PROJECT_DIR"
    - ccache --zero-stats
    # Replace CC/CXX with ccache'd versions
    - mkdir .ccache-bin/
    - if test -n "$JOB_CC"; then ln -s "$(command -pv ccache)" .ccache-bin/"$CC" && export CC="$(realpath .ccache-bin)/$CC" || exit $?; fi
    - if test -n "$JOB_CC"; then ln -s "$(command -pv ccache)" .ccache-bin/"$CXX" && export CXX="$(realpath .ccache-bin)/$CXX" || exit $?; fi
    - echo -e "\e[0Ksection_end:`date +%s`:ccache_init\r\e[0K"
  - fi

  - &postjob
    - ci/scripts/network-stats.sh .netstats.txt

  after_script:
  # Report statistics on how much ccache helped in this job
  - CCACHE_DIR="$(realpath .ccache/)" ccache --show-stats || true
  - CCACHE_DIR="$(realpath .ccache/)" ccache --show-compression || true
  # Zero the statistics to lower GitLab cache thrashing
  - CCACHE_DIR="$(realpath .ccache/)" ccache --zero-stats || true

.buildcache-job-derivative:
  extends: .buildcache-job
  cache:
  - !reference [.spack, cache]
  - <<: *bcjob_cache1
    key: bcjob-$BASE_IMAGE
  - <<: *bcjob_cache2
    key: bcjob-$BASE_IMAGE-$CI_COMMIT_REF_SLUG
  - *bcjob_cache3

# Build many versions of the codebase, to ensure all the various compilations work
# As a general rule, we sweep the most-likely-to-fail configurations by turning off a single variant
# at a time. With the exception of +debug, which is flipped at will.
.buildmany:
  stage: test
  extends: .buildcache-job
  tags: [docker, linux/$ARCH]
  image: registry.gitlab.com/hpctoolkit/ci-images/$IMAGE:$ARCH

  script:
  - touch img-config
  # Run the build script for a wide sweep of configurations. Use some Python to help.
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME/latest" -a install -a check-install
    img-config "ci/dependencies/latest;ci/dependencies/latest/$concrete"
    --spack-args='--use-buildcache=only --no-check-signature --fail-fast' --ccache-stats
    -s "$SPEC"
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME/minimum" -a install -a check-install
    img-config "ci/dependencies/minimum;ci/dependencies/minimum/$concrete"
    --spack-args='--use-buildcache=only --no-check-signature --fail-fast' --ccache-stats
    -s "$SPEC"
  - *postjob

  artifacts:
    paths:
    - logs/
    when: always

.buildmany.amd64:
  extends: .buildmany
  variables:
    ARCH: amd64
  needs:
  - job: autoreconf
    artifacts: false
  - generate_deps.amd64
  - build_deps.amd64
.buildmany.arm64:
  extends: .buildmany
  variables:
    ARCH: arm64
  needs:
  - job: autoreconf
    artifacts: false
  - generate_deps.arm64
  - build_deps.arm64

'buildmany: [amd64]':
  extends: .buildmany.amd64
  parallel:
    matrix:
    - IMAGE: almalinux8
      JOB_CC: gcc=8

    - IMAGE: leap15
      JOB_CC: gcc-11

    - IMAGE: ubuntu20.04
      JOB_CC: [gcc-9, gcc-10]

    - IMAGE: fedora36
      JOB_CC: [gcc=12]
  variables:
    SPEC: '~cuda ~rocm ~level0 (tests2 mpi papi opencl)[~<1]'

'buildmany: [arm64]':
  extends: .buildmany.arm64
  parallel:
    matrix:
    - IMAGE: ubuntu20.04
      JOB_CC: [gcc-10]
  variables:
    SPEC: '~cuda ~rocm ~level0 +debug +tests2 (mpi papi opencl)[~<1]'

'buildmany: [amd64, +cuda]':
  extends: [.buildmany.amd64, .buildcache-job-derivative]
  image: nvcr.io/nvidia/cuda:$CUDA-devel-ubuntu20.04
  parallel:
    matrix:
    - CUDA: [11.8.0]
  variables:
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:amd64
    JOB_CC: gcc-9
    SPEC: '+cuda ~rocm ~level0 +tests2 (mpi papi opencl)[~<1]'

  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config

'buildmany: [amd64, +cuda]: [10.2]':
  extends: [.buildmany.amd64, .buildcache-job-derivative]
  image: registry.gitlab.com/hpctoolkit/ci-images/almalinux8-cuda10.2:amd64
  variables:
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/almalinux8:amd64
    JOB_CC: gcc=8
    SPEC: '+cuda ~rocm ~level0 ~tests2 (mpi papi opencl)[~<1]'

  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config

'buildmany: [amd64, +rocm]':
  extends: [.buildmany.amd64, .buildcache-job-derivative]
  image: docker.io/rocm/dev-ubuntu-20.04:$ROCM
  parallel:
    matrix:
    - ROCM: [5.2.3]
  variables:
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:amd64
    JOB_CC: gcc-9
    SPEC: '~cuda +rocm ~level0 +tests2 (mpi papi opencl)[~<1]'

  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull ROCm from the image itself
  - echo '--with-rocm=/opt/rocm' > img-config

'buildmany: [amd64, +level0]':
  extends: [.buildmany.amd64, .buildcache-job-derivative]
  image: docker.io/intel/oneapi-basekit:$ONEAPI-devel-ubuntu20.04
  tags: [docker, linux/amd64]
  parallel:
    matrix:
    - ONEAPI: ['2022.2']
  variables:
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:amd64
    JOB_CC: gcc-9
    SPEC: '~cuda ~rocm +level0 +tests2 (mpi papi opencl)[~<1]'

  before_script:
  # The base Intel image has some extra elements on the PATH, make sure /usr/local/bin takes precdence
  - export PATH=/usr/local/bin:"$PATH"
  - !reference [.buildmany.amd64, before_script]
  # Pull Level 0 (part of OneAPI) from the image itself
  - echo '--with-level0=/usr' > img-config


# Build single versions of the codebase and run unit tests through `make check`
.check job:
  stage: test
  extends: .buildcache-job

  variables:
    # OpenMPI refuses to run as user 0 without these options set.
    OMPI_ALLOW_RUN_AS_ROOT: 1
    OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  script:
  - touch img-config
  # Run the test suite for the configuration of interest. Use some Python to help.
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME" -a test
    img-config "ci/dependencies/latest;ci/dependencies/latest/$concrete"
    --spack-args='--use-buildcache=only --no-check-signature --fail-fast' --ccache-stats
    --test-junit-copyout -1 -s "$SPEC"
  - *postjob

  artifacts:
    reports:
      junit: '*.junit.xml'
    paths:
    - logs/
    when: always

.check job amd64:
  extends: .check job
  variables:
    ARCH: amd64
  needs:
  - job: autoreconf
    artifacts: false
  - generate_deps.amd64
  - build_deps.amd64
.check job arm64:
  extends: .check job
  variables:
    ARCH: arm64
  needs:
  - job: autoreconf
    artifacts: false
  - generate_deps.arm64
  - build_deps.arm64

# NB: We use --repeat in the check jobs to detect bugs that cause sporadic test failures.
# We chose --repeat 7, since this statistically provides:
#   - 99.2% confidence that this MR does not introduce a "blocking" bug that would prevent others'
#     work. We are very confident that a run will succeed >1/2 the time, and so require minimal
#     repeated commands to "push past" the issue. (`1 - pbinom(0, 7, 1 - 1/2) -> 0.992`)
#   - 79.0% confidence that this MR does not introduce a bug that would "annoy" others during their
#     work. We are modestly confident that a run will succeed >4/5 of the time, in which case the
#     bug may not be especially noticable. (`1 - pbinom(0, 7, 1 - 4/5) -> 0.790`)
#
# For the curious, the key formula to solve for the --repeat value is:
#     {# of repeats} > log(1 - {confidence}) / log({min prob of success})
# So a 99% confidence of 90% success rate requires a --repeat of at least 44.

'check amd64: [cpu]':
  extends: .check job amd64
  tags: [docker, linux/$ARCH]
  image: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:$ARCH
  variables:
    JOB_CC: gcc-10
    SPEC: '+tests2 +mpi +debug +papi ~opencl ~cuda ~rocm ~level0'
    MESON_TEST_OPTS: '--maxfail 10 --repeat 7'
'check arm64: [cpu]':
  extends: .check job arm64
  tags: [docker, linux/$ARCH]
  image: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:$ARCH
  variables:
    JOB_CC: gcc-10
    SPEC: '+tests2 +mpi +debug +papi ~opencl ~cuda ~rocm ~level0'
    MESON_TEST_OPTS: '--maxfail 10'
'check amd64: [+cuda]':
  extends: [.check job amd64, .buildcache-job-derivative]
  image: nvcr.io/nvidia/cuda:11.6.2-devel-ubuntu20.04
  tags: [docker, linux/$ARCH, gpu/nvidia/usrspace:11.6, gpu/nvidia>6.0]
  variables:
    JOB_CC: gcc-9
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:$ARCH
    SPEC: +tests2 +mpi +debug +papi ~opencl +cuda ~rocm ~level0
    MESON_TEST_OPTS: '--maxfail 10 --repeat 7 --suite cuda'
  before_script:
  - !reference [.check job amd64, before_script]
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config
'check amd64: [+rocm]':
  extends: [.check job amd64, .buildcache-job-derivative]
  image: docker.io/rocm/dev-ubuntu-20.04:5.2.3
  tags: [docker, linux/$ARCH, gpu/amd/usrspace:5.2]
  variables:
    JOB_CC: gcc-9
    BASE_IMAGE: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:$ARCH
    SPEC: +tests2 +mpi +debug +papi ~opencl ~cuda +rocm ~level0
    MESON_TEST_OPTS: '--maxfail 10 --repeat 7 --suite rocm'
  before_script:
  - !reference [.check job amd64, before_script]
  # Pull ROCm from the image itself
  - echo '--with-rocm=/opt/rocm' > img-config


# Check that the Spack recipe for @develop is sufficiently up-to-date to compile this branch.
# Failures are allowed so that if the dependencies or build flags shift, we are made aware (by a
# big orange exclaimation point) but not blocked by upstream Spack.
spack install:
  stage: lint
  extends: .buildcache-job
  tags: [docker, linux/$ARCH]
  image: registry.gitlab.com/hpctoolkit/ci-images/ubuntu20.04:$ARCH
  parallel:
    matrix:
    - ARCH: [amd64]

  needs: []

  allow_failure: true
  script:
  # Spack out a representative HPCToolkit. All dependencies should be in the buildcache.
  # TODO: Expand this list a bit sometime to better represent what we want to ensure works
  - HPCTOOLKIT="hpctoolkit @git.${CI_MERGE_REQUEST_SOURCE_BRANCH_SHA:-${CI_COMMIT_SHA}}=develop"
  - >-
    eatmydata spack install --no-check-signature --fail-fast --use-buildcache=package:never,dependencies:only
    "$HPCTOOLKIT ~viewer ~mpi ~debug +papi +opencl ~cuda ~rocm ~level_zero"
    "$HPCTOOLKIT ~viewer ~mpi ~debug ~papi +opencl ~cuda ~rocm ~level_zero"
