# Only spawn workflows for MRs or protected branches
workflow:
  rules:
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
    when: never
  - when: always


stages:
- individual tests
- semi-fresh tests
- configuration tests

variables:
  # Most jobs require the submodules, those that don't will override this
  GIT_SUBMODULE_STRATEGY: recursive

  # Add a transfer progress bar for artifacts
  TRANSFER_METER_FREQUENCY: 2s

  # Use fastzip to package caches and artifacts
  FF_USE_FASTZIP: 'true'
  ARTIFACT_COMPRESSION_LEVEL: default
  CACHE_COMPRESSION_LEVEL: fastest

  # Retry various preliminary job stages (network errors)
  GET_SOURCES_ATTEMPTS: 3
  ARTIFACTS_DOWNLOAD_ATTEMPTS: 3
  EXECUTOR_JOB_SECTION_ATTEMPTS: 3


default:
  # Most jobs can be interrupted and should be retried if failed for mysterious reasons
  interruptible: true
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - stuck_or_timeout_failure
    - runner_system_failure


include:
# All code should pass pre-commit without error.
- component: gitlab.com/blue42u/ci.pre-commit/lite@0.2.0

# These images are based on classic distributions and contain no vendor software
- component: &ci_predeps gitlab.com/blue42u/ci.predeps/build@0.3.0
  inputs:
    <<: &ci_predeps_shared
      fallback_registry: registry.gitlab.com/hpctoolkit/hpctoolkit/ci.predeps
    name: rhel8-amd64
    containerfile: .ci.predeps/Containerfile.rhel8
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: ubuntu20.04-amd64
    containerfile: .ci.predeps/Containerfile.ubuntu20.04
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: ubuntu20.04-arm64
    containerfile: .ci.predeps/Containerfile.ubuntu20.04
    platform: linux/arm64
    job_tag: rice-linux-medium-arm64
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: ubuntu20.04-ppc64le
    containerfile: .ci.predeps/Containerfile.ubuntu20.04
    platform: linux/ppc64le
    job_tag: rice-linux-medium-ppc64le
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: fedora38-amd64
    containerfile: .ci.predeps/Containerfile.fedora38
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: leap15-amd64
    containerfile: .ci.predeps/Containerfile.leap15
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: bare-amd64
    containerfile: .ci.predeps/Containerfile.bare
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: bare-arm64
    containerfile: .ci.predeps/Containerfile.bare
    platform: linux/arm64
    job_tag: rice-linux-medium-arm64
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: bare-ppc64le
    containerfile: .ci.predeps/Containerfile.bare
    platform: linux/ppc64le
    job_tag: rice-linux-medium-ppc64le

# Images based on (containing) Nvidia's CUDA Toolkit
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: cuda11.6-amd64
    containerfile: .ci.predeps/Containerfile.cuda
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: cuda11.8-amd64
    containerfile: .ci.predeps/Containerfile.cuda
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: cuda12.0-amd64
    containerfile: .ci.predeps/Containerfile.cuda

# Images based on (containing) AMD's ROCm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.1-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.2-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.3-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.4-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.5-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.6-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm5.7-amd64
    containerfile: .ci.predeps/Containerfile.rocm
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: rocm6.0-amd64
    containerfile: .ci.predeps/Containerfile.rocm

# Image(s) based on (containing) Intel's Level Zero, IGC, GTPin, etc.
- component: *ci_predeps
  inputs:
    <<: *ci_predeps_shared
    name: intel-amd64
    containerfile: .ci.predeps/Containerfile.intel

'predeps: [rhel8-amd64]':
  before_script: &predeps_before_script
  - export PREDEPS_SECRET_spack_mirrors=/tmp/mirrors.yaml
  - >-
    printf "mirrors: {%s: {url: '%s', access_pair: ['%s', '%s'], binary: true, source: false}}"
    __ci_remote_cache_push_mirror oci://"$CI_REGISTRY_IMAGE"/spack-buildcache/v0.21
    "$CI_REGISTRY_USER" "$CI_REGISTRY_PASSWORD"
    > "$PREDEPS_SECRET_spack_mirrors"
'predeps: [ubuntu20.04-amd64]':
  before_script: *predeps_before_script
'predeps: [ubuntu20.04-arm64]':
  before_script: *predeps_before_script
'predeps: [ubuntu20.04-ppc64le]':
  before_script: *predeps_before_script
'predeps: [fedora38-amd64]':
  before_script: *predeps_before_script
'predeps: [leap15-amd64]':
  before_script: *predeps_before_script
'predeps: [bare-amd64]':
  before_script: *predeps_before_script
'predeps: [bare-arm64]':
  before_script: *predeps_before_script
'predeps: [bare-ppc64le]':
  before_script: *predeps_before_script

'predeps: [cuda11.6-amd64]':
  variables:
    PREDEPS_BUILD_ARG_CUDA_VERSION: '11.6.2'
  before_script: *predeps_before_script
'predeps: [cuda11.8-amd64]':
  variables:
    PREDEPS_BUILD_ARG_CUDA_VERSION: '11.8.0'
  before_script: *predeps_before_script
'predeps: [cuda12.0-amd64]':
  variables:
    PREDEPS_BUILD_ARG_CUDA_VERSION: '12.0.1'
  before_script: *predeps_before_script

'predeps: [rocm5.1-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.1.3'
  before_script: *predeps_before_script
'predeps: [rocm5.2-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.2.3'
  before_script: *predeps_before_script
'predeps: [rocm5.3-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.3.3'
  before_script: *predeps_before_script
'predeps: [rocm5.4-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.4.3'
  before_script: *predeps_before_script
'predeps: [rocm5.5-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.5.1'
  before_script: *predeps_before_script
'predeps: [rocm5.6-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.6.1'
  before_script: *predeps_before_script
'predeps: [rocm5.7-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '5.7.1'
  before_script: *predeps_before_script
'predeps: [rocm6.0-amd64]':
  variables:
    PREDEPS_BUILD_ARG_ROCM_VERSION: '6.0'
  before_script: *predeps_before_script

'predeps: [intel-amd64]':
  before_script: *predeps_before_script


# The vast majority of jobs in this sequence do a build and then run some tests. This is the base
# job spec for such jobs, configurable via a small number of variables.
# NB: We use --repeat in these jobs to detect bugs that cause sporadic test failures.
# We chose --repeat 7, since this statistically provides:
# - 99.2% confidence that this MR does not introduce a "blocking" bug that would prevent others'
#   work. We are very confident that a run will succeed >1/2 the time, and so require minimal
#   repeated commands to "push past" the issue. (`1 - pbinom(0, 7, 1 - 1/2) -> 0.992`)
# - 79.0% confidence that this MR does not introduce a bug that would "annoy" others during their
#   work. We are modestly confident that a run will succeed >4/5 of the time, in which case the
#   bug may not be especially noticable. (`1 - pbinom(0, 7, 1 - 4/5) -> 0.790`)
# Also, --repeat 7 is low enough that it doesn't slow down the CI too much.
#
# For the curious, the key formula to solve for the --repeat value is:
#     {# of repeats} > log(1 - {confidence}) / log({min prob of success})
# So a 99% confidence of 90% success rate requires a --repeat of at least 44.
.test job:
  cache:
  - key: meson-packagecache
    when: always
    paths:
    - subprojects/packagecache
  - key: ccache-$CI_JOB_NAME
    when: always
    paths:
    - .ccache/
  variables:
    CCACHE_DIR: '$CI_PROJECT_DIR/.ccache'
    SETUP_ARGS: ''
    TEST_ARGS: ''
    # OpenMPI refuses to run as user 0 without these options set.
    OMPI_ALLOW_RUN_AS_ROOT: 1
    OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  script:
  - &test_job_setup
    - mkdir -p logs
    # If we don't have sufficient perf events support, try to enable it.
    - if [ "$(cat /proc/sys/kernel/perf_event_paranoid)" -gt 1 ]; then echo 1 > /proc/sys/kernel/perf_event_paranoid; fi
    # We also want kernel symbols available (kallsyms), so enable that too.
    - if [ "$(cat /proc/sys/kernel/kptr_restrict)" -gt 0 ]; then echo 0 > /proc/sys/kernel/kptr_restrict; fi
    # Usual sequence from here: setup, build and test
    - >-
      meson setup
      --native-file image.ini
      -Dauto_features=enabled
      --wrap-mode=nofallback
      $SETUP_ARGS builddir
  - meson compile -C builddir 2>&1 | tee compile.log
  - meson compile -C builddir lint-depends
  - if [ "$TEST_ARGS" != NOTESTS ]; then meson test -C builddir --maxfail 3 --repeat 7 $TEST_ARGS; fi
  after_script:
  - |
    echo "To reproduce this build, run:"
    echo "    podman run --rm -it -v ./:/hpctoolkit:ro --workdir /hpctoolkit \\"
    echo "      -e OMPI_ALLOW_RUN_AS_ROOT=1 -e OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 \\"
    echo "      -e SETUP_ARGS='$SETUP_ARGS' -e TEST_ARGS='$TEST_ARGS'$EXTRA_ENVS \\"
    echo "      $CI_JOB_IMAGE"
    echo "and repeat the commands listed in the job log above, with builddir replaced with /tmp/builddir."
    echo "If using VSCode, you may also try using the appropriate devcontainer."
  - if [ -f compile.log ]; then ./ci/cc-diagnostics.py cq.json compile.log; fi
  artifacts:
    reports:
      codequality: cq.json
      junit: builddir/meson-logs/testlog.junit.xml
    when: always


# Individual test runs, each on a single known software stack
.individual test job:
  extends: .test job
  stage: individual tests
.individual test job std:
  extends: .individual test job
  tags: [saas-linux-small-amd64]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=$FALLBACKS
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
ubuntu20.04 amd64:
  extends: .individual test job std
  needs: ['predeps: [ubuntu20.04-amd64]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_AMD64
  variables:
    FALLBACKS: dyninst,elfutils,libunwind,xed,xxhash
ubuntu20.04 arm64:
  extends: .individual test job std
  needs: ['predeps: [ubuntu20.04-arm64]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_ARM64
  tags: [rice-linux-small-arm64]
  variables:
    FALLBACKS: dyninst,elfutils,libunwind,xed,xxhash
ubuntu20.04 ppc64le:
  extends: .individual test job std
  needs: ['predeps: [ubuntu20.04-ppc64le]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_PPC64LE
  tags: [rice-linux-small-ppc64le]
  variables:
    FALLBACKS: dyninst,elfutils,libunwind,xed,xxhash
leap15 amd64:
  extends: .individual test job std
  needs: ['predeps: [leap15-amd64]']
  image: $PREDEPS_IMAGE_LEAP15_AMD64
  variables:
    FALLBACKS: dyninst,elfutils,libunwind,xed
rhel8 amd64:
  extends: .individual test job std
  needs: ['predeps: [rhel8-amd64]']
  image: $PREDEPS_IMAGE_RHEL8_AMD64
  variables:
    FALLBACKS: dyninst,libunwind,xed
    # FIXME: MVAPICH2 reacts badly in VMs, it claims to have no threading support. The same effect
    # can't be reproduced in a local container, for whatever reason. Disable the MPI tests on this
    # MPI for now until a proper fix can be figured out.
    TEST_ARGS: --no-suite mpi
fedora38 amd64:
  extends: .individual test job std
  needs: ['predeps: [fedora38-amd64]']
  image: $PREDEPS_IMAGE_FEDORA38_AMD64
  variables:
    FALLBACKS: dyninst,xed
    # FIXME: This particular version of OpenMPI reacts badly in VMs, hpcprof-mpi hangs. The same
    # effect can't be reproduced in a local container, for whatever reason. Disable the MPI tests
    # on this MPI for now until a proper fix can be figured out.
    TEST_ARGS: --no-suite mpi

.individual test job bare:
  extends: .individual test job
  tags: [saas-linux-medium-amd64]
  variables:
    SETUP_ARGS: >-
      --wrap-mode=default
      -Dzstd:lz4=disabled
      -Dpython=disabled
      -Dhpcprof_mpi=disabled
      -Dpapi=disabled
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
bare amd64:
  extends: .individual test job bare
  needs: ['predeps: [bare-amd64]']
  image: $PREDEPS_IMAGE_BARE_AMD64
bare arm64:
  extends: .individual test job bare
  needs: ['predeps: [bare-arm64]']
  image: $PREDEPS_IMAGE_BARE_ARM64
  tags: [rice-linux-small-arm64]
bare ppc64le:
  extends: .individual test job bare
  needs: ['predeps: [bare-ppc64le]']
  image: $PREDEPS_IMAGE_BARE_PPC64LE
  tags: [rice-linux-small-ppc64le]

.individual test job cuda:
  extends: .individual test job
  tags: [rice-linux-large-amd64-gpu-p100]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    TEST_ARGS: >-
      --suite cuda
      --suite hpcstruct
cuda11.6 amd64:
  extends: .individual test job cuda
  needs: ['predeps: [cuda11.6-amd64]']
  image: $PREDEPS_IMAGE_CUDA11_6_AMD64
cuda11.8 amd64:
  extends: .individual test job cuda
  needs: ['predeps: [cuda11.8-amd64]']
  image: $PREDEPS_IMAGE_CUDA11_8_AMD64
cuda12.0 amd64:
  extends: .individual test job cuda
  needs: ['predeps: [cuda12.0-amd64]']
  image: $PREDEPS_IMAGE_CUDA12_0_AMD64

.individual test job rocm:
  extends: .individual test job
  tags: [rice-linux-large-amd64-gpu-amd]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Dcuda=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    TEST_ARGS: >-
      --suite rocm
rocm5.1 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.1-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_1_AMD64
  variables:
    # FIXME: For some reason the RUNPATHs don't work for ROCm 5.1 specifically. Not sure if anyone
    # uses this version anymore, so for now hack it to work.
    LD_LIBRARY_PATH: /opt/rocm/lib
rocm5.2 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.2-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_2_AMD64
rocm5.3 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.3-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_3_AMD64
rocm5.4 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.4-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_4_AMD64
rocm5.5 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.5-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_5_AMD64
rocm5.6 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.6-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_6_AMD64
rocm5.7 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm5.7-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_7_AMD64
rocm6.0 amd64:
  extends: .individual test job rocm
  needs: ['predeps: [rocm6.0-amd64]']
  image: $PREDEPS_IMAGE_ROCM6_0_AMD64

intel amd64:
  # FIXME: Currently we have no tests that require Intel hardware nor any Intel
  # hardware connected to CI! Until the situation improves, run all the tests
  # but enable level0 and gtpin (so we at least build with something different).
  # We need a *-medium-* runner here because the Intel images are huge.
  extends: .individual test job std
  tags: [saas-linux-medium-amd64]
  needs: ['predeps: [intel-amd64]']
  image: $PREDEPS_IMAGE_INTEL_AMD64
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash,gtpin
      -Dcuda=disabled
      -Drocm=disabled


# Selected semi-fresh test runs. These regenerate suitable parts of the test data
# before running the tests, thus testing that "freshening" the test data doesn't
# break any tests. For example, an uncaught change to the output format.
.semifresh test job:
  extends: .test job
  stage: semi-fresh tests
  variables:
    REGEN_SUITES: ''
  script:
  - *test_job_setup
  - meson compile -C builddir $(printf 'regen-testdata-%s\n' $REGEN_SUITES)
  - git add --intent-to-add tests2/data/
  - meson compile -C builddir $(printf 'patches-testdata-%s\n' $REGEN_SUITES)
  - mkdir testdata-patches/
  - cp -t testdata-patches/ builddir/tests2/data/*.patch
  # Make sure we run the tests once in the same build directory that generated them
  - meson test -C builddir --maxfail 3 $TEST_ARGS
  # Then wipe the build directory and re-test against a "sterilized" build
  - meson setup --wipe builddir
  - meson test -C builddir --maxfail 3 --repeat 6 $TEST_ARGS
  after_script:
  - EXTRA_ENVS=" -e REGEN_SUITES='$REGEN_SUITES'"
  - !reference [.test job, after_script]
  artifacts:
    expire_in: 1 day
    reports:
      junit: builddir/meson-logs/testlog.junit.xml
    paths:
    - testdata-patches/
    when: always
semifresh none cpu:
  extends: .semifresh test job
  needs: ['predeps: [ubuntu20.04-amd64]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_AMD64
  tags: [saas-linux-medium-amd64]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    REGEN_SUITES: none cpu
semifresh nvidia sw-cuda:
  extends: .semifresh test job
  needs: ['predeps: [cuda11.8-amd64]']
  image: $PREDEPS_IMAGE_CUDA11_8_AMD64
  tags: [rice-linux-large-amd64-gpu-p100]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    REGEN_SUITES: nvidia sw-cuda
semifresh amd:
  extends: .semifresh test job
  needs: ['predeps: [rocm5.7-amd64]']
  image: $PREDEPS_IMAGE_ROCM5_7_AMD64
  tags: [rice-linux-large-amd64-gpu-amd]
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Dcuda=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    REGEN_SUITES: amd

# For easy access, the regenerated test data is made available as a single job artifact archive
fresh testdata:
  stage: semi-fresh tests
  image: docker.io/alpine
  needs:
  - semifresh none cpu
  - semifresh nvidia sw-cuda
  - semifresh amd
  when: always
  script:
  - apk add git
  - ls -l testdata-patches/
  - git apply --index --check -- testdata-patches/*.patch
  artifacts:
    expose_as: "Test data refresh patches"
    expire_in: 3 days
    paths:
    - testdata-patches/


# Compiler compatibility checks. There are a lot of different breeds of compilers out there,
# and we want to be widely compatible with a wide range of them. Test the ones that aren't
# the defaults in the individual tests, and ensure the wraps are tested here as well.
.compiler compat test job:
  extends: .test job
  stage: configuration tests
  tags: [saas-linux-small-amd64]
compiler gcc8:
  extends: .compiler compat test job
  needs: ['predeps: [rhel8-amd64]']
  image: $PREDEPS_IMAGE_RHEL8_AMD64
  variables:
    SETUP_ARGS: >-
      --wrap-mode=forcefallback
      -Dzstd:lz4=disabled
      --native-file gcc.ini
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    # FIXME: MVAPICH2 reacts badly in VMs, it claims to have no threading support. The same effect
    # can't be reproduced in a local container, for whatever reason. Disable the MPI tests on this
    # MPI for now until a proper fix can be figured out.
    TEST_ARGS: --no-suite mpi
compiler clang10:
  extends: .compiler compat test job
  needs: ['predeps: [ubuntu20.04-amd64]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_AMD64
  variables:
    SETUP_ARGS: >-
      --wrap-mode=forcefallback
      -Dzstd:lz4=disabled
      --native-file clang10.ini
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
compiler clang16:
  extends: .compiler compat test job
  needs: ['predeps: [fedora38-amd64]']
  image: $PREDEPS_IMAGE_FEDORA38_AMD64
  variables:
    SETUP_ARGS: >-
      --wrap-mode=forcefallback
      -Dzstd:lz4=disabled
      --native-file clang.ini
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
    # FIXME: This particular version of OpenMPI reacts badly in VMs, hpcprof-mpi hangs. The same
    # effect can't be reproduced in a local container, for whatever reason. Disable the MPI tests
    # on this MPI for now until a proper fix can be figured out.
    TEST_ARGS: --no-suite mpi


# Non-default option checks. There are a small number of options that users/packagers can
# configure to their whims. These tests check that changing them from the defaults doesn't
# break anything along the way.
.option test job:
  extends: .test job
  stage: configuration tests
  tags: [saas-linux-small-amd64]
'option: [ubuntu20.04 amd64]':
  extends: .option test job
  needs: ['predeps: [ubuntu20.04-amd64]']
  image: $PREDEPS_IMAGE_UBUNTU20_04_AMD64
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
      $OPTION
  parallel:
    matrix:
    - OPTION:
      - --buildtype=release
      - -Dvalgrind_annotations=true
    - OPTION:
      - -Dpapi=disabled
      - -Dpython=disabled
      - -Dopencl=disabled
      TEST_ARGS: --suite hpcrun
    - OPTION: -Dhpcprof_mpi=disabled
      TEST_ARGS: NOTESTS
'option: [bare amd64]':
  extends: .option test job
  needs: ['predeps: [bare-amd64]']
  image: $PREDEPS_IMAGE_BARE_AMD64
  variables:
    SETUP_ARGS: >-
      --wrap-mode=default
      -Dzstd:lz4=disabled
      -Dpython=disabled
      -Dhpcprof_mpi=disabled
      -Dcuda=disabled
      -Drocm=disabled
      -Dlevel0=disabled
      -Dgtpin=disabled
      -Dpapi=disabled
      $OPTION
  parallel:
    matrix:
    - OPTION:
      - --buildtype=release
      - -Dvalgrind_annotations=true
    - OPTION:
      - -Dopencl=disabled
      TEST_ARGS: --suite hpcrun
'option: [intel amd64]':
  extends: .option test job
  needs: ['predeps: [intel-amd64]']
  image: $PREDEPS_IMAGE_INTEL_AMD64
  variables:
    SETUP_ARGS: >-
      --force-fallback-for=dyninst,elfutils,libunwind,xed,xxhash
      -Dcuda=disabled
      -Drocm=disabled
      $OPTION
  parallel:
    matrix:
    - OPTION: -Dgtpin=disabled
      TEST_ARGS: --suite hpcrun


# Check that Spack develop can properly build HPCToolkit in a small matrix of configurations.
'spack install':
  stage: configuration tests
  image:
    name: ghcr.io/spack/fedora37:develop
    entrypoint: ['spack-env']
  needs:
  - job: 'predeps: [fedora38-amd64]'  # Reuses buildcache from this image
    artifacts: false
  tags: [saas-linux-medium-amd64]
  rules:
  - if: $CI_COMMIT_REF_PROTECTED == "true"
    allow_failure: false
  - allow_failure: true
  cache:
  - key: spack-src
    paths:
    - .cache/spack-src/
  before_script:
  - mkdir -p .cache/spack-src
  - >-
    spack config add config:source_cache:"$CI_PROJECT_DIR"/.cache/spack-src
  - >-
    test -z "$CI_REGISTRY" ||
    spack mirror add --oci-username "$CI_REGISTRY_USER" --oci-password "$CI_REGISTRY_PASSWORD"
    --type binary remote-cache oci://"$CI_REGISTRY_IMAGE"/spack-buildcache/v0.21
  script:
  - spack env create -d /tmp/env ci/tests.spack.yaml
  - spack -D /tmp/env install --fail-fast --no-check-signature
  after_script:
  - |
    echo "To reproduce:"
    echo "    cd path/to/hpctoolkit"
    echo "    podman run --rm -it -v ./:/hpctoolkit:O --workdir /hpctoolkit $CI_JOB_IMAGE"
