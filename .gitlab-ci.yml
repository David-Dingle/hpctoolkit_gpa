# Only spawn workflows for MRs or protected branches
workflow:
  rules:
  - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"'
    when: never
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
    when: never
  - when: always


stages:
- deps:generate
- deps:prep
- deps:build
- deps:package
- deps
- validate
- manual
- test
- lint


include:
# Jobs for building all the dependencies with Spack
- local: ci/dependencies/.gitlab-ci.yml
# Jobs for constructing the container images used in CI
- local: ci/containers/.gitlab-ci.yml

.rebuild images:
  rules:
  - if: $CI_COMMIT_REF_PROTECTED == "true"
  - if: '$CI_MERGE_REQUEST_LABELS =~ /ci: rebuild images/'
  - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    changes:
    - ci/dependencies/latest/spack.yaml
    - ci/dependencies/minimum/spack.yaml
    - ci/containers/**/*


variables:
  # Most jobs don't needs submodules, those that do will override this.
  GIT_SUBMODULE_STRATEGY: none

  # Add a transfer progress bar for artifacts
  TRANSFER_METER_FREQUENCY: 2s

  # Use fastzip to package caches and artifacts
  FF_USE_FASTZIP: 'true'
  ARTIFACT_COMPRESSION_LEVEL: default
  CACHE_COMPRESSION_LEVEL: fastest

  # Retry various preliminary job stages (network errors)
  GET_SOURCES_ATTEMPTS: 3
  ARTIFACTS_DOWNLOAD_ATTEMPTS: 3
  EXECUTOR_JOB_SECTION_ATTEMPTS: 3


default:
  # Most jobs can be interrupted and should be retried if failed for mysterious reasons
  interruptible: true
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - stuck_or_timeout_failure
    - runner_system_failure

  # By default, use a Docker runner with a late-model CI image
  tags: [docker]


# Pre-commit linting passes must pass for the pipeline to succeed
precommit:
  stage: lint
  tags: [docker, linux/amd64]
  image: docker.io/python:3.10-bullseye
  needs: []
  before_script:
  - python3 -m pip install pre-commit
  script:
  - pre-commit run --all-files --show-diff-on-failure


# The Autogoo for the HEAD commit (at least) must be in-sync before we build
autoreconf:
  stage: validate
  tags: [docker, linux/amd64]
  image: $DEPS_IMAGES-ubuntu20.04-amd64
  needs:
  - 'deps: [amd64]'
  before_script: &autoconf
  - export PATH=/spack/cenv/_autogen/view/bin:"$PATH"
  - export AUTOCONF=/spack/cenv/_autogen/view/bin/autoconf
  - export ACLOCAL=/spack/cenv/_autogen/view/bin/aclocal
  - export AUTOHEADER=/spack/cenv/_autogen/view/bin/autoheader
  - export AUTOM4TE=/spack/cenv/_autogen/view/bin/autom4te
  - export AUTOMAKE=/spack/cenv/_autogen/view/bin/automake
  - export LIBTOOLIZE=/spack/cenv/_autogen/view/bin/libtoolize
  - export M4=/spack/cenv/_autogen/view/bin/m4
  script:
  - ./autogen > autogen.log
  - git status --porcelain=v1 --untracked-files=no > changes || exit $?
  - |
    if test -s changes; then
      echo "== CHANGES DETECTED, running git diff..."
      git diff | tee fixup.patch
      echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
      exit 1
    fi
  artifacts:
    when: always
    paths:
    - autogen.log
    - fixup.patch


# Also check that the Autogoo is in-sync for all commits that will be merged,
# but only if merged results pipelines are enabled.
autoreconf check:
  stage: lint
  tags: [docker, linux/amd64]
  image: $DEPS_IMAGES-ubuntu20.04-amd64
  needs:
  - autoreconf
  - 'deps: [amd64]'

  allow_failure: true
  variables:
    GIT_DEPTH: 100
  rules:
  - if: $CI_MERGE_REQUEST_TARGET_BRANCH_SHA
  before_script: *autoconf
  script:
  - TARG="$(git show --no-patch --pretty=reference $CI_MERGE_REQUEST_TARGET_BRANCH_SHA)"
  - SRC="$(git show --no-patch --pretty=reference $CI_MERGE_REQUEST_SOURCE_BRANCH_SHA)"
  - MERGE="$(git show --no-patch --pretty=reference HEAD)"
  - echo "Checking commit range $TARG..$SRC + $MERGE"
  - git rev-list --topo-order --reverse HEAD ^"$CI_MERGE_REQUEST_TARGET_BRANCH_SHA" > revs
  - |
    while read rev; do
      echo
      echo "== Checking $(git show --no-patch --pretty=reference $rev)" | tee -a autogen.log
      git checkout --force "$rev" || exit $?
      git clean -fxd || exit $?
      ./autogen >> autogen.log || exit $?
      git status --porcelain=v1 --untracked-files=no > changes || exit $?
      if test -s changes; then
        echo "== CHANGES DETECTED, running git diff..."
        git diff | tee fixup.patch
        echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
        echo "== First noticed desynchronization in commit:"
        git show --no-patch --pretty=medium $rev
        exit 1
      fi
    done < revs
  artifacts:
    when: always
    paths:
    - autogen.log
    - fixup.patch


# Allow manually triggering a child pipeline to regenerate the test data
regen testdata:
  stage: manual
  when: manual
  allow_failure: true
  trigger:
    include:
    - local: tests2/data/.gitlab-ci.yml
  variables:
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID
    GIT_SUBMODULE_STRATEGY: recursive


# Build jobs require a working Spack and compilers and a few other bits. This job handles that setup.
.build-job:
  cache:
  - key: pkgs-$IMAGE_BASE
    when: always
    paths:
    - .pkg-cache/
  - key: ccache-$IMAGE_BASE$IMAGE_EXT-$JOB_CC
    when: always
    paths:
    - .ccache/

  variables:
    CCACHE_DIR: '$CI_PROJECT_DIR/.ccache'
    CCACHE_BASEDIR: '$CI_PROJECT_DIR'
    # Limit the ccache cache size to a modest level.
    # One HPCToolkit buildmany is ~2.5GB (~600MB compressed) over ~25000 files
    CCACHE_COMPRESS: 'true'
    CCACHE_MAXSIZE: '3G'
    CCACHE_MAXFILES: '30000'

  before_script:
  # Zero the ccache statistics for accurate measurements in the builds
  - ccache --zero-stats
  - BUILD_REPROD_ARGS=()

  after_script:
  # Zero the ccache statistics to lower GitLab cache thrashing (maybe)
  - ccache --zero-stats


# Build many versions of the codebase, to ensure all the various compilations work
# As a general rule, we sweep the most-likely-to-fail configurations by turning off a single variant
# at a time. With the exception of +debug, which is flipped at will.
.buildmany:
  stage: test
  extends: .build-job
  tags: [docker, linux/$ARCH]
  image: $DEPS_IMAGES-$IMAGE_BASE-$ARCH

  before_script:
  - !reference [.build-job, before_script]
  - REPROD_ARGS=(--reproducible)
  - REPROD_ARGS+=(--reproduction-cmd 'touch img-config')
  script:
  - touch img-config
  # Run the build script for a wide sweep of configurations. Use some Python to help.
  - rm -rf logs/
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME/latest" -c "$JOB_CC" -a check-install
    img-config "ci/dependencies/latest;/spack/cenv/latest" --spack-no-install --ccache-stats
    "${BUILD_REPROD_ARGS[@]}" "${REPROD_ARGS[@]}" -s "$SPEC"
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME/minimum" -c "$JOB_CC" -a check-install
    img-config "ci/dependencies/minimum;/spack/cenv/minimum" --spack-no-install --ccache-stats
    "${BUILD_REPROD_ARGS[@]}" "${REPROD_ARGS[@]}" -s "$SPEC"

  artifacts:
    paths:
    - logs/
    when: always

.buildmany.amd64:
  extends: .buildmany
  variables:
    ARCH: amd64
  needs:
  - job: autoreconf
    artifacts: false
  - 'deps: [amd64]'
.buildmany.arm64:
  extends: .buildmany
  variables:
    ARCH: arm64
  needs:
  - job: autoreconf
    artifacts: false
  - 'deps: [arm64]'

'buildmany: [amd64]':
  extends: .buildmany.amd64
  parallel:
    matrix:
    - IMAGE_BASE: almalinux8
      JOB_CC: gcc=8

    - IMAGE_BASE: leap15
      JOB_CC: gcc-11

    - IMAGE_BASE: ubuntu20.04
      JOB_CC: [gcc-9, gcc-10, clang-10]

    - IMAGE_BASE: fedora37
      JOB_CC: [gcc=12, clang=15]
  variables:
    SPEC: '~cuda ~rocm ~level0 !debug (tests2 mpi papi opencl python)[~<1]'
'buildmany: [arm64]':
  extends: .buildmany.arm64
  parallel:
    matrix:
    - IMAGE_BASE: ubuntu20.04
      JOB_CC: [gcc-10]
  variables:
    SPEC: '~cuda ~rocm ~level0 +debug +tests2 (mpi papi opencl python)[~<1]'

'buildmany: [amd64, +cuda]':
  extends: .buildmany.amd64
  image: $DEPS_IMAGES-ubuntu20.04-cuda$CUDA-$ARCH
  parallel:
    matrix:
    - CUDA: [11.8.0, 12.0.1]
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +cuda
    JOB_CC: gcc-9
    SPEC: '+cuda ~rocm ~level0 !debug +tests2 (mpi papi opencl python)[~<1]'
    NVIDIA_VISIBLE_DEVICES: ''  # We're just building, no need to access hardware
  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config
'buildmany: [amd64, +cuda]: [10.2]':
  extends: .buildmany.amd64
  image: $DEPS_IMAGES-almalinux8-cuda10.2-$ARCH
  variables:
    IMAGE_BASE: almalinux8
    IMAGE_EXT: +cuda
    JOB_CC: gcc=8
    SPEC: '+cuda ~rocm ~level0 !debug ~tests2 (mpi papi opencl python)[~<1]'
    NVIDIA_VISIBLE_DEVICES: ''  # We're just building, no need to access hardware
  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config

'buildmany: [amd64, +rocm]':
  extends: .buildmany.amd64
  image: $DEPS_IMAGES-ubuntu20.04-rocm$ROCM-$ARCH
  parallel:
    matrix:
    - ROCM: [5.1.3, 5.2.3, 5.3.2, 5.4.2]
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +rocm
    JOB_CC: gcc-9
    SPEC: '~cuda +rocm ~level0 !debug +tests2 (mpi papi opencl python)[~<1]'
  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull ROCm from the image itself
  - echo '--with-rocm=/opt/rocm' > img-config

'buildmany: [amd64, +level0]':
  extends: .buildmany.amd64
  image: $DEPS_IMAGES-ubuntu20.04-lvlz$ONEAPI-$ARCH
  tags: [docker, linux/amd64]
  parallel:
    matrix:
    - ONEAPI: ['2022.2', '2022.3.1', '2023.0.0']
      GTPIN: ['3.0', '3.2.2']
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +intel
    JOB_CC: gcc-9
    SPEC: '~cuda ~rocm +level0 !debug +tests2 (mpi papi opencl python gtpin)[~<1]'
  before_script:
  - !reference [.buildmany.amd64, before_script]
  # Pull Level 0 (part of OneAPI), IGC and GTPin from the image + packages themselves
  - echo '--with-level0=/usr' > img-config
  - echo '--with-igc=/usr' >> img-config
  - echo "--with-gtpin=/opt/gtpin-$GTPIN/Profilers" >> img-config


# Build single versions of the codebase and run unit tests through `make check`
.check job:
  stage: test
  extends: .build-job

  variables:
    CENV: latest
    # Some of the test data is stored in a submodule
    GIT_SUBMODULE_STRATEGY: recursive
    # OpenMPI refuses to run as user 0 without these options set.
    OMPI_ALLOW_RUN_AS_ROOT: 1
    OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  script:
  - touch img-config
  - rm -rf logs/
  # For semifresh runs, regenerate some of the test data before testing. Use some Python to help.
  - >-
    test -z "$REGEN" ||
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME/regen" -c "$JOB_CC" ${REGEN}
    img-config "ci/dependencies/$CENV;/spack/cenv/$CENV"
    --spack-no-install --ccache-stats --fresh-unpack
    "${BUILD_REPROD_ARGS[@]}" "${REPROD_ARGS[@]}" -1 -s "$SPEC"
  # Run the test suite for the configuration of interest. Use some Python to help.
  - >-
    eatmydata python3 -m ci.buildfe -l "logs/$CI_JOB_NAME" -c "$JOB_CC" -a test
    img-config "ci/dependencies/$CENV;/spack/cenv/$CENV"
    --spack-no-install --ccache-stats --test-junit-copyout
    "${BUILD_REPROD_ARGS[@]}" "${REPROD_ARGS[@]}" -1 -s "$SPEC"

  artifacts:
    reports:
      junit: '*.junit.xml'
    paths:
    - logs/
    when: always
.check min:
  variables:
    CENV: minimum
.check semifresh:
  stage: test
  variables:
    REGEN: '-a fresh-testdata-none'

.check job amd64:
  extends: .check job
  variables:
    ARCH: amd64
  needs:
  - job: autoreconf
    artifacts: false
  - 'deps: [amd64]'
.check semifresh amd64:
  extends: .check semifresh
  dependencies:
  - 'deps: [amd64]'
.check job arm64:
  extends: .check job
  variables:
    ARCH: arm64
  needs:
  - job: autoreconf
    artifacts: false
  - 'deps: [arm64]'
.check semifresh arm64:
  extends: .check semifresh
  dependencies:
  - 'deps: [arm64]'

# NB: We use --repeat in the check jobs to detect bugs that cause sporadic test failures.
# We chose --repeat 7, since this statistically provides:
#   - 99.2% confidence that this MR does not introduce a "blocking" bug that would prevent others'
#     work. We are very confident that a run will succeed >1/2 the time, and so require minimal
#     repeated commands to "push past" the issue. (`1 - pbinom(0, 7, 1 - 1/2) -> 0.992`)
#   - 79.0% confidence that this MR does not introduce a bug that would "annoy" others during their
#     work. We are modestly confident that a run will succeed >4/5 of the time, in which case the
#     bug may not be especially noticable. (`1 - pbinom(0, 7, 1 - 4/5) -> 0.790`)
#
# For the curious, the key formula to solve for the --repeat value is:
#     {# of repeats} > log(1 - {confidence}) / log({min prob of success})
# So a 99% confidence of 90% success rate requires a --repeat of at least 44.

'check amd64: [cpu]':
  extends: .check job amd64
  tags: [docker, linux/$ARCH]
  image: $DEPS_IMAGES-ubuntu20.04-$ARCH
  variables:
    JOB_CC: gcc-10
    SPEC: '+tests2 +mpi +debug +papi +python ~opencl ~cuda ~rocm ~level0'
  before_script:
  - !reference [.check job amd64, before_script]
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10 --repeat 7"
'check min amd64: [cpu]':
  extends: ['check amd64: [cpu]', .check min]
'check semifresh amd64: [cpu]':
  extends: ['check amd64: [cpu]', .check semifresh amd64]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'
'check arm64: [cpu]':
  extends: .check job arm64
  tags: [docker, linux/$ARCH]
  image: $DEPS_IMAGES-ubuntu20.04-$ARCH
  variables:
    JOB_CC: gcc-10
    SPEC: '+tests2 +mpi +debug +papi +python ~opencl ~cuda ~rocm ~level0'
  before_script:
  - !reference [.check job arm64, before_script]
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10"
'check min arm64: [cpu]':
  extends: ['check arm64: [cpu]', .check min]
'check semifresh arm64: [cpu]':
  extends: ['check arm64: [cpu]', .check semifresh arm64]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'

'check amd64: [+cuda, 11.6.2]':
  extends: .check job amd64
  image: $DEPS_IMAGES-ubuntu20.04-cuda11.6.2-$ARCH
  tags: [docker, linux/$ARCH, gpu/nvidia/usrspace:11.6, gpu/nvidia>6.0]
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +cuda
    JOB_CC: gcc-9
    SPEC: +tests2 +mpi +debug +papi +python ~opencl +cuda ~rocm ~level0
  before_script:
  - !reference [.check job amd64, before_script]
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10 --repeat 7 --suite cuda"
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config
'check min amd64: [+cuda, 11.6.2]':
  extends: ['check amd64: [+cuda, 11.6.2]', .check min]
'check semifresh amd64: [+cuda, 11.6.2]':
  extends: ['check amd64: [+cuda, 11.6.2]', .check semifresh amd64]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu -a fresh-testdata-nvidia'

'check amd64: [+cuda, 11.8.0]':
  extends: .check job amd64
  image: $DEPS_IMAGES-ubuntu20.04-cuda11.8.0-$ARCH
  tags: [docker, linux/$ARCH]
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +cuda
    JOB_CC: gcc-9
    SPEC: +tests2 +mpi +debug +papi +python ~opencl +cuda ~rocm ~level0
    NVIDIA_VISIBLE_DEVICES: ''  # Disallow GPU access
  before_script:
  - !reference [.check job amd64, before_script]
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10 --repeat 7"
  # Pull CUDA from the image itself
  - echo '--with-cuda=/usr/local/cuda' > img-config
'check min amd64: [+cuda, 11.8.0]':
  extends: ['check amd64: [+cuda, 11.8.0]', .check min]
'check semifresh amd64: [+cuda, 11.8.0]':
  extends: ['check amd64: [+cuda, 11.8.0]', .check semifresh amd64]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'

'check amd64: [+rocm]':
  extends: .check job amd64
  image: $DEPS_IMAGES-ubuntu20.04-rocm5.2.3-$ARCH
  tags: [docker, linux/$ARCH, gpu/amd/usrspace:5.2]
  variables:
    IMAGE_BASE: ubuntu20.04
    IMAGE_EXT: +rocm
    JOB_CC: gcc-9
    SPEC: +tests2 +mpi +debug +papi +python ~opencl ~cuda +rocm ~level0
  before_script:
  - !reference [.check job amd64, before_script]
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10 --repeat 7 --suite rocm"
  # Pull ROCm from the image itself
  - echo '--with-rocm=/opt/rocm' > img-config
'check min amd64: [+rocm]':
  extends: ['check amd64: [+rocm]', .check min]
'check semifresh amd64: [+rocm]':
  extends: ['check amd64: [+rocm]', .check semifresh amd64]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu -a fresh-testdata-amd'


# Perform linting tasks that can only be done when the whole build is complete
lint:
  stage: lint
  needs:
  - 'buildmany: [amd64]'
  - 'buildmany: [arm64]'
  - 'buildmany: [amd64, +cuda]'
  - 'buildmany: [amd64, +cuda]: [10.2]'
  - 'buildmany: [amd64, +rocm]'
  - 'buildmany: [amd64, +level0]'
  - 'check amd64: [cpu]'
  - 'check min amd64: [cpu]'
  - 'check semifresh amd64: [cpu]'
  - 'check arm64: [cpu]'
  - 'check min arm64: [cpu]'
  - 'check semifresh arm64: [cpu]'
  - 'check amd64: [+cuda, 11.6.2]'
  - 'check min amd64: [+cuda, 11.6.2]'
  - 'check semifresh amd64: [+cuda, 11.6.2]'
  - 'check amd64: [+cuda, 11.8.0]'
  - 'check min amd64: [+cuda, 11.8.0]'
  - 'check semifresh amd64: [+cuda, 11.8.0]'
  - 'check amd64: [+rocm]'
  - 'check min amd64: [+rocm]'
  - 'check semifresh amd64: [+rocm]'
  when: always

  image: docker.io/python:3.11-alpine
  script:
  # Merge all the code quality results into a single file, for use by GitLab
  - ./ci/scripts/merge-cq cq.json logs/**/*.cq.json

  artifacts:
    reports:
      codequality: cq.json


# Check that the Spack recipe for @develop is sufficiently up-to-date to compile this branch.
# Failures are allowed so that if the dependencies or build flags shift, we are made aware (by a
# big orange exclaimation point) but not blocked by upstream Spack.
'spack install: [amd64]':
  stage: lint
  tags: [docker, linux/amd64]
  image: $DEPS_IMAGES-ubuntu20.04-amd64
  needs: ['deps: [amd64]']
  allow_failure: true
  cache:
    key: spack
    when: always
    paths: [.spack.git]
  script:
  # Instantiate Spack
  - export SPACK_ROOT="$(realpath .spack)" PATH="$(realpath .spack)"/bin:"$PATH"
  - ci/dependencies/spack-init.sh
  # Spack out a representative HPCToolkit. All dependencies should already be built.
  # TODO: Expand this list a bit sometime to better represent what we want to ensure works
  - HPCTOOLKIT="hpctoolkit @git.${CI_MERGE_REQUEST_SOURCE_BRANCH_SHA:-${CI_COMMIT_SHA}}=develop"
  - >-
    eatmydata spack install --fail-fast
    "$HPCTOOLKIT ~viewer ~mpi ~debug +papi +opencl ~cuda ~rocm ~level_zero"
    "$HPCTOOLKIT ~viewer ~mpi ~debug ~papi +opencl ~cuda ~rocm ~level_zero"
