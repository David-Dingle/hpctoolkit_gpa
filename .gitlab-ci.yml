# Only spawn workflows for MRs or protected branches
workflow:
  rules:
  - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"'
    when: never
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED != "true"
    when: never
  - when: always


stages:
- setup:gen
- setup:build
- validate
- manual
- test
- lint


variables:
  # Most jobs don't needs submodules, those that do will override this.
  GIT_SUBMODULE_STRATEGY: none

  # Add a transfer progress bar for artifacts
  TRANSFER_METER_FREQUENCY: 2s

  # Use fastzip to package caches and artifacts
  FF_USE_FASTZIP: 'true'
  ARTIFACT_COMPRESSION_LEVEL: default
  CACHE_COMPRESSION_LEVEL: fastest

  # Retry various preliminary job stages (network errors)
  GET_SOURCES_ATTEMPTS: 3
  ARTIFACTS_DOWNLOAD_ATTEMPTS: 3
  EXECUTOR_JOB_SECTION_ATTEMPTS: 3


default:
  # Most jobs can be interrupted and should be retried if failed for mysterious reasons
  interruptible: true
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - stuck_or_timeout_failure
    - runner_system_failure


# Many jobs need a working copy of the ./dev scriptsuite. This job handles setting it up.
.dev job:
  before_script:
  # Install the ./dev scriptsuite in a virtual environment
  - python3 -m venv .dev_venv --clear --upgrade-deps --system-site-packages
  - export PATH="$(realpath .dev_venv/bin/):$PATH"
  - pip install --no-cache-dir --require-virtualenv lib/dev/

# Many jobs use ccache to speed up the build process. This job provides common settings for those.
.ccache job:
  cache:
  - key: ccache-$CI_JOB_NAME
    when: always
    paths:
    - .ccache/

  variables:
    CCACHE_DIR: '$CI_PROJECT_DIR/.ccache'
    CCACHE_BASEDIR: '$CI_PROJECT_DIR'
    CCACHE_NOCOMPRESS: 'true'
    CCACHE_MAXSIZE: '5G'
    CCACHE_MAXFILES: '0'

#----------------------------------------------
# Phase 1: setup:*
#----------------------------------------------

# Generate a matrix of Dockerfiles for all the "spins" we test in CI
setup:gen:
  extends: .dev job
  stage: setup:gen
  image:
    name: ghcr.io/spack/fedora37:latest
    entrypoint: ['spack-env']
  variables:
    MODE: '--any'
  needs: []
  before_script:
  - spack --version
  - yum list installed python3-devel || yum install -y python3-devel
  - !reference [.dev job, before_script]
  # Prepare to generate spins
  - mkdir imgctxs/
  - |
    genimg() {
      set -x

      # Generate the devenv using the appropriate arguments
      dev generate "$MODE" imgctxs/"$1" \
        --template ci/spins/base.yaml --template ci/spins/"$1".yaml || return $?
      # Insert the symlink needed to access the templates
      ln -sr ci/templates imgctxs/"$1"/templates || return $?
      # Generate the complete Dockerfile
      (cd imgctxs/"$1" && spack --env-dir=. containerize > Dockerfile) || return $?
      if echo "$1" | grep -q fedora; then
        # The Fedoras do not have (or need) EPEL. See https://github.com/spack/spack/issues/37765
        sed -i -e 's/yum install -y epel-release \&\&//g' imgctxs/"$1"/Dockerfile || return $?
      fi
      # The Spack recipe doesn't quite handle APT with update:false right.
      # See https://github.com/spack/spack/issues/37772
      sed -i -e 's/apt-get -yqq install/apt-get -yqq update \&\& \0/g' imgctxs/"$1"/Dockerfile || return $?
      # Clean up the mess
      rm -r imgctxs/"$1"/.spack-env/ || return $?
      rm imgctxs/"$1"/.gitignore imgctxs/"$1"/templates || return $?

      set +x
    }
  script:
  - if test "$CI_COMMIT_REF_PROTECTED" = "true"; then export MODE="--latest"; fi
  # CPU-only spins
  - genimg leap15
  - genimg almalinux8
  - genimg ubuntu20.04
  - genimg fedora37
  # CUDA spins
  - genimg cuda10.2
  - genimg cuda11.6.2
  - genimg cuda11.8.0
  - genimg cuda12.0.1
  # ROCm spins
  - genimg rocm5.1.3
  - genimg rocm5.2.3
  - genimg rocm5.3.2
  - genimg rocm5.4.2
  # Level 0 + GTPin spins
  - genimg lvlz2022.2-gtpin3.0
  - genimg lvlz2022.2-gtpin3.2.2
  - genimg lvlz2022.3.1-gtpin3.0
  - genimg lvlz2022.3.1-gtpin3.2.2
  - genimg lvlz2023.0.0-gtpin3.0
  - genimg lvlz2023.0.0-gtpin3.2.2
  artifacts:
    paths:
    - imgctxs/
setup:gen min:
  extends: setup:gen
  variables:
    MODE: '--minimum'
setup:gen autogen:
  extends: setup:gen
  variables:
    MODE: '--autogen'
  script:
  # We only need one spin for the autogen job
  - genimg ubuntu20.04
  - echo '{}' > imgctxs/ubuntu20.04/dev.json

# For each spin generated in above, build an image for it below
.setup:build:
  stage: setup:build
  image: quay.io/buildah/stable
  retry: 2
  needs: [setup:gen]
  before_script:
  # Log into the registry
  - sudo -u build buildah login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  - IMAGE=$BASE${EXT:+-}$EXT
  # Set up the cache and command
  - mkdir -p .buildah-cache/
  - chown -R build:build .buildah-cache/
  - ln -s $CI_PROJECT_DIR/.buildah-cache/ /var/tmp/buildah-cache-$(id -u build)
  - bdah() { sudo -Eu build buildah "$@"; }
  script:
  - test "$SPIN"
  - test "$MODE"
  - cache="$CI_REGISTRY_IMAGE/cache"
  - tag="$CI_REGISTRY_IMAGE/ci:$CI_COMMIT_SHA-$SPIN-$ARCH"
  - cp ci/templates/cuda.repo.amd64 imgctxs/"$SPIN"/
  # Build the image we will use moving forward
  - >-
    bdah build --secret id=spack_mirrors,src="$SBCACHE_YAML"
    --layers --cache-from="$cache" --cache-to="$cache"
    --tag="$tag" --arch="$ARCH" --format=docker
    imgctxs/"$SPIN"/
  # Push up the built image, and save the digest
  - bdah push --digestfile=digest "$tag"
  # Propagate an environment variable to refer to this image in later jobs
  - slug="$(echo "${ARCH}_${SPIN}_${MODE}" | sed 's/[^a-zA-Z0-9_]/_/g')"
  - echo "IMAGE_$slug=$tag@$(cat digest)" | tee out.env
  artifacts:
    reports:
      dotenv: out.env

'setup:build: [amd64]':
  extends: .setup:build
  tags: [saas-linux-small-amd64]
  variables:
    ARCH: amd64
    MODE: main
  parallel:
    matrix:
    - SPIN:
      # CPU-only spins
      - leap15
      - almalinux8
      - ubuntu20.04
      - fedora37
      # CUDA spins
      - cuda10.2
      - cuda11.6.2
      - cuda11.8.0
      - cuda12.0.1
      # ROCm spins
      - rocm5.1.3
      - rocm5.2.3
      - rocm5.3.2
      - rocm5.4.2
      # Level 0 + GTPin spins
      - lvlz2022.2-gtpin3.0
      - lvlz2022.2-gtpin3.2.2
      - lvlz2022.3.1-gtpin3.0
      - lvlz2022.3.1-gtpin3.2.2
      - lvlz2023.0.0-gtpin3.0
      - lvlz2023.0.0-gtpin3.2.2
'setup:build min: [amd64]':
  extends: 'setup:build: [amd64]'
  needs: [setup:gen min]
  variables:
    MODE: minimum

'setup:build: [arm64]':
  extends: .setup:build
  tags: [rice-linux-small-arm64]
  variables:
    ARCH: arm64
    MODE: main
  parallel:
    matrix:
    - SPIN:
      - ubuntu20.04
'setup:build min: [arm64]':
  extends: 'setup:build: [arm64]'
  needs: [setup:gen min]
  variables:
    MODE: minimum

'setup:build autogen':
  extends: .setup:build
  needs: [setup:gen autogen]
  tags: [saas-linux-small-amd64]
  variables:
    ARCH: amd64
    SPIN: ubuntu20.04
    MODE: fixed

#-----------------------------------
# Phase N: lint
#-----------------------------------

# Pre-commit linting passes must pass for the pipeline to succeed
precommit:
  stage: lint
  image: docker.io/python:3.10-bullseye
  needs: []
  before_script:
  - python3 -m pip install pre-commit
  script:
  - pre-commit run --all-files --show-diff-on-failure


# Check that the Spack recipe for @develop is sufficiently up-to-date to compile this branch.
# Failures are allowed so that if the dependencies or build flags shift, we are made aware (by a
# big orange exclaimation point) but not blocked by upstream Spack.
'spack install: [amd64]':
  stage: lint
  image: $IMAGE_amd64_ubuntu20_04_main
  needs: ['setup:build: [amd64]: [ubuntu20.04]']
  tags: [saas-linux-small-amd64]
  allow_failure: true
  cache:
    key: spack
    when: always
    paths: [.spack.git]
  script:
  # Instantiate a fresh Spack develop (instead of whatever is burned into the image)
  - |
    if [ ! -d .spack.git ]; then
      git clone --depth=30 --single-branch --no-tags --branch=develop --bare \
        https://github.com/spack/spack.git .spack.git || exit $?
    fi
  - git -C .spack.git fetch --verbose origin +develop:develop
  - git clone --shared --branch=develop .spack.git .spack
  - export PATH="$(realpath .spack)"/bin:"$PATH"
  # Spack out a representative HPCToolkit. All dependencies should already be built.
  # TODO: Expand this list a bit sometime to better represent what we want to ensure works
  - HPCTOOLKIT="hpctoolkit @git.${CI_MERGE_REQUEST_SOURCE_BRANCH_SHA:-${CI_COMMIT_SHA}}=develop"
  - >-
    eatmydata spack install --fail-fast --add
    "$HPCTOOLKIT ~viewer ~mpi ~debug +papi +opencl ~cuda ~rocm ~level_zero"
    "$HPCTOOLKIT ~viewer ~mpi ~debug ~papi +opencl ~cuda ~rocm ~level_zero"

#-----------------------------------
# Phase 2: validate
#-----------------------------------

# The two devenvs must be consistent with the current version of the ./dev scriptsuite.
deps check:
  extends: .dev job
  stage: validate
  image: $IMAGE_amd64_ubuntu20_04_main
  needs: ['setup:build: [amd64]: [ubuntu20.04]']
  tags: [saas-linux-small-amd64]
  script:
  - dev populate /opt/spack-environment
  - dev env -d /opt/spack-environment echo OK


# The Autogoo for the HEAD commit (at least) must be in-sync before we build
autoreconf:
  extends: [.dev job]
  stage: validate
  image: $IMAGE_amd64_ubuntu20_04_fixed
  needs: ['setup:build autogen']
  tags: [saas-linux-small-amd64]
  script:
  - dev autogen --custom-env /opt/spack-environment --skip-install
  - git status --porcelain=v1 --untracked-files=no > changes || exit $?
  - |
    if test -s changes; then
      echo "== CHANGES DETECTED, running git diff..."
      git diff | tee fixup.patch
      echo "== AUTOGOO OUT-OF-SYNC, see patch above and in fixup.patch for details"
      exit 1
    fi
  artifacts:
    when: always
    paths:
    - fixup.patch

#-----------------------------------
# Phase 2.5: manual
#-----------------------------------

# Allow manually triggering a child pipeline to regenerate the test data
regen testdata:
  stage: manual
  when: manual
  allow_failure: true
  trigger:
    include:
    - local: tests2/data/.gitlab-ci.yml
  variables:
    PARENT_IMAGE_amd64_ubuntu20_04: $IMAGE_amd64_ubuntu20_04_latest
    PARENT_IMAGE_amd64_cuda11_6_2: $IMAGE_amd64_cuda11_6_2_latest
    PARENT_IMAGE_amd64_cuda11_8_0: $IMAGE_amd64_cuda11_8_0_latest
    PARENT_IMAGE_amd64_rocm5_2_3: $IMAGE_amd64_rocm5_2_3_latest
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID
    GIT_SUBMODULE_STRATEGY: recursive


#-----------------------------------
# Phase 3: test
#-----------------------------------

# Build many versions of the codebase, to ensure all the various compilations work
# As a general rule, we sweep the most-likely-to-fail configurations by turning off a single variant
# at a time. With the exception of +debug, which is flipped at will.
.buildmany:
  extends: .dev job
  stage: test
  script:
  - dev populate /opt/spack-environment
  # Run the build script for a wide sweep of configurations. Use some Python to help.
  - rm -rf logs/
  - >-
    eatmydata dev buildfe -d /opt/spack-environment --
    -l "logs/$CI_JOB_NAME" -c "$JOB_CC" -a check-install
    --ccache-stats --fail-fast --reproducible $OS_BUILDFE_ARGS -s "$SPEC"
  after_script:
  - ./ci/scripts/merge-cq cq.json logs/**/*.cq.json
  artifacts:
    reports:
      codequality: cq.json
    paths:
    - logs/
    when: always

# CPU-only spins
.buildmany amd64 cpu:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    SPEC: '~cuda ~rocm ~level0 !debug (tests2 mpi papi opencl python)[~<1]'
.buildmany arm64 cpu:
  extends: .buildmany
  tags: [rice-linux-small-arm64]
  variables:
    SPEC: '~cuda ~rocm ~level0 +debug +tests2 (mpi papi opencl python)[~<1]'

'buildmany: [amd64, almalinux8]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_almalinux8_main
  needs:
  - 'setup:build: [amd64]: [almalinux8]'
  - &deps_check
    job: deps check
    artifacts: false
  - &autoreconf
    job: autoreconf
    artifacts: false
  parallel: {matrix: [{JOB_CC: gcc=8}]}
'buildmany: [amd64, ubuntu20.04]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_ubuntu20_04_main
  needs: ['setup:build: [amd64]: [ubuntu20.04]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: [gcc-9, gcc-10, clang-10]}]}
'buildmany: [arm64, ubuntu20.04]':
  extends: .buildmany arm64 cpu
  image: $IMAGE_arm64_ubuntu20_04_main
  needs: ['setup:build: [arm64]: [ubuntu20.04]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: gcc-10}]}
'buildmany: [amd64, leap15]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_leap15_main
  needs: ['setup:build: [amd64]: [leap15]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: gcc-11}]}
'buildmany: [amd64, fedora37]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_fedora37_main
  needs: ['setup:build: [amd64]: [fedora37]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: [gcc=12, clang=15]}]}

'buildmany min: [amd64, almalinux8]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_almalinux8_minimum
  needs: ['setup:build min: [amd64]: [almalinux8]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: gcc=8}]}
'buildmany min: [amd64, ubuntu20.04]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_ubuntu20_04_minimum
  needs: ['setup:build min: [amd64]: [ubuntu20.04]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: [gcc-9, gcc-10, clang-10]}]}
'buildmany min: [arm64, ubuntu20.04]':
  extends: .buildmany arm64 cpu
  image: $IMAGE_arm64_ubuntu20_04_minimum
  needs: ['setup:build min: [arm64]: [ubuntu20.04]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: gcc-10}]}
'buildmany min: [amd64, leap15]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_leap15_minimum
  needs: ['setup:build min: [amd64]: [leap15]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: gcc-11}]}
'buildmany min: [amd64, fedora37]':
  extends: .buildmany amd64 cpu
  image: $IMAGE_amd64_fedora37_minimum
  needs: ['setup:build min: [amd64]: [fedora37]', *deps_check, *autoreconf]
  parallel: {matrix: [{JOB_CC: [gcc=12, clang=15]}]}


# CUDA spins
.buildmany amd64 cuda:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    OS_BUILDFE_ARGS: '-C--with-cuda=/usr/local/cuda'
    SPEC: '+cuda ~rocm ~level0 !debug +tests2 (mpi papi opencl python)[~<1]'

'buildmany: [amd64, cuda12.0.1]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda12_0_1_main
  needs: ['setup:build: [amd64]: [cuda12.0.1]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, cuda11.8.0]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda11_8_0_main
  needs: ['setup:build: [amd64]: [cuda11.8.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, cuda10.2]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda10_2_main
  needs: ['setup:build: [amd64]: [cuda10.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc=8
    # The tests2 suite is not expected to operate on CUDA 10.2
    SPEC: &cuda102_min_spec '+cuda ~rocm ~level0 !debug ~tests2 (mpi papi opencl python)[~<1]'

'buildmany min: [amd64, cuda12.0.1]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda12_0_1_minimum
  needs: ['setup:build min: [amd64]: [cuda12.0.1]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, cuda11.8.0]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda11_8_0_minimum
  needs: ['setup:build min: [amd64]: [cuda11.8.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, cuda10.2]':
  extends: .buildmany amd64 cuda
  image: $IMAGE_amd64_cuda10_2_minimum
  needs: ['setup:build min: [amd64]: [cuda10.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc=8
    SPEC: *cuda102_min_spec

# ROCm spins
.buildmany amd64 rocm:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    OS_BUILDFE_ARGS: '-C--with-rocm=/opt/rocm'
    SPEC: '~cuda +rocm ~level0 !debug +tests2 (mpi papi opencl python)[~<1]'

'buildmany: [amd64, rocm5.1.3]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_1_3_main
  needs: ['setup:build: [amd64]: [rocm5.1.3]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, rocm5.2.3]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_2_3_main
  needs: ['setup:build: [amd64]: [rocm5.2.3]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, rocm5.3.2]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_3_2_main
  needs: ['setup:build: [amd64]: [rocm5.3.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, rocm5.4.2]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_4_2_main
  needs: ['setup:build: [amd64]: [rocm5.4.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9

'buildmany min: [amd64, rocm5.1.3]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_1_3_minimum
  needs: ['setup:build min: [amd64]: [rocm5.1.3]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, rocm5.2.3]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_2_3_minimum
  needs: ['setup:build min: [amd64]: [rocm5.2.3]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, rocm5.3.2]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_3_2_minimum
  needs: ['setup:build min: [amd64]: [rocm5.3.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, rocm5.4.2]':
  extends: .buildmany amd64 rocm
  image: $IMAGE_amd64_rocm5_4_2_minimum
  needs: ['setup:build min: [amd64]: [rocm5.4.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9

# Level 0 + GTPin spins
.buildmany amd64 lvlz:
  extends: .buildmany
  tags: [saas-linux-small-amd64]
  variables:
    OS_BUILDFE_ARGS: '-C--with-level0=/usr -C--with-igc=/usr -C--with-gtpin=/opt/gtpin/Profilers'
    SPEC: '~cuda ~rocm +level0 !debug +tests2 (mpi papi opencl python gtpin)[~<1]'

'buildmany: [amd64, lvlz2022.2, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_2_gtpin3_0_main
  needs: ['setup:build: [amd64]: [lvlz2022.2-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, lvlz2022.2, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_2_gtpin3_2_2_main
  needs: ['setup:build: [amd64]: [lvlz2022.2-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, lvlz2022.3.1, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_3_1_gtpin3_0_main
  needs: ['setup:build: [amd64]: [lvlz2022.3.1-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, lvlz2022.3.1, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_3_1_gtpin3_2_2_main
  needs: ['setup:build: [amd64]: [lvlz2022.3.1-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, lvlz2023.0.0, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2023_0_0_gtpin3_0_main
  needs: ['setup:build: [amd64]: [lvlz2023.0.0-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany: [amd64, lvlz2023.0.0, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2023_0_0_gtpin3_2_2_main
  needs: ['setup:build: [amd64]: [lvlz2023.0.0-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9

'buildmany min: [amd64, lvlz2022.2, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_2_gtpin3_0_minimum
  needs: ['setup:build min: [amd64]: [lvlz2022.2-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, lvlz2022.2, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_2_gtpin3_2_2_minimum
  needs: ['setup:build min: [amd64]: [lvlz2022.2-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, lvlz2022.3.1, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_3_1_gtpin3_0_minimum
  needs: ['setup:build min: [amd64]: [lvlz2022.3.1-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, lvlz2022.3.1, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2022_3_1_gtpin3_2_2_minimum
  needs: ['setup:build min: [amd64]: [lvlz2022.3.1-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, lvlz2023.0.0, gtpin3.0]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2023_0_0_gtpin3_0_minimum
  needs: ['setup:build min: [amd64]: [lvlz2023.0.0-gtpin3.0]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9
'buildmany min: [amd64, lvlz2023.0.0, gtpin3.2.2]':
  extends: .buildmany amd64 lvlz
  image: $IMAGE_amd64_lvlz2023_0_0_gtpin3_2_2_minimum
  needs: ['setup:build min: [amd64]: [lvlz2023.0.0-gtpin3.2.2]', *deps_check, *autoreconf]
  variables:
    JOB_CC: gcc-9


# Build single versions of the codebase and run unit tests through `make check`
# NB: We use --repeat in the check jobs to detect bugs that cause sporadic test failures.
# We chose --repeat 7, since this statistically provides:
#   - 99.2% confidence that this MR does not introduce a "blocking" bug that would prevent others'
#     work. We are very confident that a run will succeed >1/2 the time, and so require minimal
#     repeated commands to "push past" the issue. (`1 - pbinom(0, 7, 1 - 1/2) -> 0.992`)
#   - 79.0% confidence that this MR does not introduce a bug that would "annoy" others during their
#     work. We are modestly confident that a run will succeed >4/5 of the time, in which case the
#     bug may not be especially noticable. (`1 - pbinom(0, 7, 1 - 4/5) -> 0.790`)
#
# For the curious, the key formula to solve for the --repeat value is:
#     {# of repeats} > log(1 - {confidence}) / log({min prob of success})
# So a 99% confidence of 90% success rate requires a --repeat of at least 44.
.check:
  extends: .dev job
  stage: test
  variables:
    # Some of the test data is stored in a submodule
    GIT_SUBMODULE_STRATEGY: recursive
    # OpenMPI refuses to run as user 0 without these options set.
    OMPI_ALLOW_RUN_AS_ROOT: 1
    OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  script:
  - dev populate /opt/spack-environment
  - export MESON_TEST_OPTS="$MESON_TEST_OPTS --maxfail 10 --repeat 7 $JOB_MESON_TEST_OPTS"
  - rm -rf logs/
  # For semifresh runs, regenerate some of the test data before testing. Use some Python to help.
  - >-
    test -z "$REGEN" ||
    eatmydata dev buildfe -d /opt/spack-environment --
    -l "logs/$CI_JOB_NAME/regen" -c "$JOB_CC" ${REGEN}
    --ccache-stats --fail-fast --fresh-unpack --reproducible $OS_BUILDFE_ARGS -1 -s "$SPEC"
  # Run the test suite for the configuration of interest. Use some Python to help.
  - >-
    eatmydata dev buildfe -d /opt/spack-environment --
    -l "logs/$CI_JOB_NAME" -c "$JOB_CC" -a test
    --ccache-stats --fail-fast --test-junit-copyout --reproducible $OS_BUILDFE_ARGS -1 -s "$SPEC"

  after_script:
  - ./ci/scripts/merge-cq cq.json logs/**/*.cq.json

  artifacts:
    reports:
      codequality: cq.json
      junit: '*.junit.xml'
    paths:
    - logs/
    when: always

'check amd64: [cpu]':
  extends: .check
  image: $IMAGE_amd64_ubuntu20_04_main
  needs: ['setup:build: [amd64]: [ubuntu20.04]', *deps_check, *autoreconf]
  tags: [saas-linux-large-amd64, cpu/perf]
  variables: &vars_check_cpu
    JOB_CC: gcc-10
    SPEC: '+tests2 +mpi +debug +papi +python ~opencl ~cuda ~rocm ~level0'
'check min amd64: [cpu]':
  extends: .check
  image: $IMAGE_amd64_ubuntu20_04_minimum
  needs: ['setup:build min: [amd64]: [ubuntu20.04]', *deps_check, *autoreconf]
  tags: [saas-linux-large-amd64, cpu/perf]
  variables: *vars_check_cpu
'check semifresh amd64: [cpu]':
  extends: 'check amd64: [cpu]'
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'

'check arm64: [cpu]':
  extends: .check
  image: $IMAGE_arm64_ubuntu20_04_main
  needs: ['setup:build: [arm64]: [ubuntu20.04]', *deps_check, *autoreconf]
  tags: [rice-linux-small-arm64, cpu/perf]
  variables:
    <<: *vars_check_cpu
    JOB_MESON_TEST_OPTS: '--repeat 1'
'check min arm64: [cpu]':
  extends: .check
  image: $IMAGE_arm64_ubuntu20_04_minimum
  needs: ['setup:build min: [arm64]: [ubuntu20.04]', *deps_check, *autoreconf]
  tags: [rice-linux-small-arm64, cpu/perf]
  variables:
    <<: *vars_check_cpu
    JOB_MESON_TEST_OPTS: '--repeat 1'
'check semifresh arm64: [cpu]':
  extends: 'check arm64: [cpu]'
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'

'check amd64: [+cuda, 11.6.2]':
  extends: .check
  image: $IMAGE_amd64_cuda11_6_2_main
  needs: ['setup:build: [amd64]: [cuda11.6.2]', *deps_check, *autoreconf]
  tags: [rice-linux-large-amd64+nvidia, gpu/nvidia/usrspace:11.6, gpu/nvidia>6.0]
  variables: &vars_check_cuda
    OS_BUILDFE_ARGS: '-C--with-cuda=/usr/local/cuda'
    JOB_CC: gcc-9
    SPEC: +tests2 +mpi +debug +papi +python ~opencl +cuda ~rocm ~level0
    JOB_MESON_TEST_OPTS: '--suite cuda'
'check min amd64: [+cuda, 11.6.2]':
  extends: .check
  image: $IMAGE_amd64_cuda11_6_2_minimum
  needs: ['setup:build min: [amd64]: [cuda11.6.2]', *deps_check, *autoreconf]
  tags: [rice-linux-large-amd64+nvidia, gpu/nvidia/usrspace:11.6, gpu/nvidia>6.0]
  variables: *vars_check_cuda
'check semifresh amd64: [+cuda, 11.6.2]':
  extends: 'check amd64: [+cuda, 11.6.2]'
  tags: [rice-linux-large-amd64+nvidia, gpu/nvidia/usrspace:11.6, gpu/nvidia>6.0, cpu/perf]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu -a fresh-testdata-nvidia'

'check amd64: [+cuda, 11.8.0]':
  extends: .check
  image: $IMAGE_amd64_cuda11_8_0_main
  needs: ['setup:build: [amd64]: [cuda11.8.0]', *deps_check, *autoreconf]
  tags: [saas-linux-large-amd64]
  variables:
    <<: *vars_check_cuda
    NVIDIA_VISIBLE_DEVICES: ''  # Disallow GPU access
'check min amd64: [+cuda, 11.8.0]':
  extends: .check
  image: $IMAGE_amd64_cuda11_8_0_minimum
  needs: ['setup:build min: [amd64]: [cuda11.8.0]', *deps_check, *autoreconf]
  tags: [saas-linux-large-amd64]
  variables:
    <<: *vars_check_cuda
    NVIDIA_VISIBLE_DEVICES: ''  # Disallow GPU access
'check semifresh amd64: [+cuda, 11.8.0]':
  extends: 'check amd64: [+cuda, 11.8.0]'
  tags: [saas-linux-large-amd64, cpu/perf]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu'

'check amd64: [+rocm]':
  extends: .check
  image: $IMAGE_amd64_rocm5_2_3_main
  needs: ['setup:build: [amd64]: [rocm5.2.3]', *deps_check, *autoreconf]
  tags: [rice-linux-large-amd64+amd, gpu/amd/usrspace:5.2]
  variables: &vars_check_rocm
    OS_BUILDFE_ARGS: '-C--with-rocm=/opt/rocm'
    JOB_CC: gcc-9
    SPEC: +tests2 +mpi +debug +papi +python ~opencl ~cuda +rocm ~level0
    JOB_MESON_TEST_OPTS: '--suite rocm'
'check min amd64: [+rocm]':
  extends: .check
  image: $IMAGE_amd64_rocm5_2_3_minimum
  needs: ['setup:build min: [amd64]: [rocm5.2.3]', *deps_check, *autoreconf]
  tags: [rice-linux-large-amd64+amd, gpu/amd/usrspace:5.2]
  variables: *vars_check_rocm
'check semifresh amd64: [+rocm]':
  extends: 'check amd64: [+rocm]'
  tags: [rice-linux-large-amd64+amd, gpu/amd/usrspace:5.2, cpu/perf]
  variables:
    REGEN: '-a fresh-testdata-none -a fresh-testdata-cpu -a fresh-testdata-amd'
